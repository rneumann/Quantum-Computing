%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Grundlegende Anwendungsgebiete}
\label{trends} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

\chapterauthor{Isabel Fritz, Felix Goos, Martin Maier, David Richard, Sabine Weigand,
Lola Bankai, Mareike Rennebaum, Siri Wandel, Hüma Yilmaz}

\abstract{some abstract}

\section{Kryptographie}
\subsection{Einleitung}
Kryptographische Verfahren sind integraler Bestandteil moderner digitaler Infrastrukturen. Insbesondere asymmetrische Kryptosysteme wie RSA, Diffie-Hellman und elliptische Kurvenkryptographie basieren auf der angenommenen Schwierigkeit mathematischer Probleme wie der ganzzahligen Faktorisierung oder der Berechnung diskreter Logarithmen. Diese Probleme gelten im klassischen Rechenmodell als nur mit exponentiellem Aufwand lösbar, wodurch die genannten Verfahren als sicher eingestuft werden. Symmetrische Kryptographie, beispielsweise AES, bietet hingegen Sicherheitsgarantien auf Basis der Schlüsselraumgröße und ist gegenwärtig gegenüber klassischen Angriffen hinreichend resistent.

Diese Sicherheitsannahmen werden jedoch durch die Entwicklung leistungsfähiger Quantencomputer substanziell infrage gestellt. Mit Shors Algorithmus (Shor 1994) wurde erstmals ein quantenmechanisches Verfahren vorgestellt, das die Faktorisierung großer Zahlen sowie die Berechnung diskreter Logarithmen in polynomialer Zeit ermöglicht und somit die Grundlage nahezu aller etablierten asymmetrischen Verfahren kompromittiert. Ergänzend dazu führt Grovers Algorithmus zu einer quadratischen Beschleunigung von Suchproblemen, was insbesondere symmetrische Verfahren betrifft, bei denen dadurch eine effektive Halbierung der Schlüssellänge notwendig wird, um das ursprüngliche Sicherheitsniveau zu erhalten (Grover 1996; vgl. auch Shor u Grover, Überblick in [63]).

Diese Algorithmen stellen keine abstrakten theoretischen Bedrohungen dar, sondern begründen bereits heute reale Risiken, insbesondere im Kontext sogenannter Harvest-now-decrypt-later-Angriffe. In diesem Szenario werden verschlüsselte Kommunikationsinhalte langfristig gespeichert, um sie bei Verfügbarkeit eines hinreichend leistungsfähigen Quantencomputers retrospektiv zu entschlüsseln (Mosca 2018). Die praktische Relevanz ergibt sich dabei aus der Latenz zwischen dem heutigen Einsatz kryptographischer Verfahren und der potentiellen Verfügbarkeit skalierbarer Quantencomputer. Michele Mosca beschreibt diese Problematik entlang dreier Größen: der angestrebten Geheimhaltungsdauer (x), der Migrationszeit zu quantenresistenten Verfahren (y) und der geschätzten Zeit bis zum Bruch aktueller Verfahren (z). Ist x + y > z, besteht akuter Handlungsbedarf, da zukünftige Angreifer auf heute übertragene Daten zugreifen können, ohne dass dies zum Zeitpunkt der Kommunikation verhindert werden kann (Mosca S. 38f.).

Diese Bedrohungslage hat eine breite wissenschaftliche, industrielle und regulatorische Reaktion ausgelöst. Insbesondere die vom U.S. National Institute of Standards and Technology (NIST) koordinierte Standardisierung postquantenkryptographischer Verfahren zielt darauf ab, praktikable Alternativen zu heute verbreiteten Algorithmen zu identifizieren, zu evaluieren und langfristig zu etablieren. Im Rahmen der vierten Wettbewerbsrunde wurden Verfahren wie CRYSTALS-Kyber, CRYSTALS-Dilithium und SPHINCS+ als zukünftige Standards ausgewählt \cite{alagic_status_2025}.

Das vorliegende Kapitel analysiert diese Entwicklung aus kryptographischer Perspektive. Es beginnt mit der detaillierten Darstellung der durch Quantenalgorithmen verursachten Bedrohung für symmetrische und asymmetrische Kryptosysteme und ordnet das Harvest-now-decrypt-later-Szenario systematisch ein. Daran anschließend werden aktuelle technische, normative und strategische Reaktionen untersucht. Ziel ist es, die Implikationen für die Gestaltung zukunftsfähiger Sicherheitssysteme darzustellen und die Notwendigkeit einer rechtzeitigen und koordinierten Umstellung auf quantenresistente Verfahren herauszuarbeiten.

\subsection{Technologische Grundlagen}
\subsubsection{Post-Quantum-Cryptography}


\subsubsection{Quantum-Key-Distribution}
\subsubsection{Quantum-Random-Number-Generator}

\subsection{Aktuelle Anwendungsprojekte}
\subsubsection{Post-Quantum-Cryptography}
\cite{}
Im Rahmen der Post-Quantum-Kryptographie-Standardisierung verfolgt das NIST das Ziel, kryptographische Algorithmen zu identifizieren, die auch gegenüber zukünftigen Quantenangriffen resistent sind. Die vierte Runde des PQC-Prozesses hat zur Auswahl von Verfahren für Public-Key-Verschlüsselung sowie digitale Signaturen geführt. Im Fokus stehen insbesondere die Verfahren CRYSTALS-Kyber, CRYSTALS-Dilithium, and SPHINCS+, welche bereits breite Beachtung in industriellen Pilotprojekten und Implementierungsstudien gefunden haben.

CRYSTALS-Kyber ist ein auf dem Module-Learning-with-Errors (Module-LWE)-Problem basierendes Verfahren zur sicheren Schlüsselaushandlung. Das Design legt besonderen Wert auf eine effiziente Implementierbarkeit über verschiedene Plattformen hinweg, darunter auch ressourcenbeschränkte Systeme wie eingebettete Geräte. Ein wesentliches Merkmal ist die Resistenz gegen Seitenkanalangriffe, insbesondere durch eine auf konstante Laufzeit ausgelegte Referenzimplementierung (vgl. NIST IR 8545, S. 4; kyber blog). Kyber wurde frühzeitig in praktische Anwendungen integriert. So testete Google gemeinsam mit Cloudflare den Algorithmus im Rahmen einer hybriden TLS-1.3-Implementierung, um dessen Praxistauglichkeit im Internetverkehr zu evaluieren. Auch Amazon Web Services (AWS) integrierte Kyber im Key Management Service als experimentellen Post-Quantum-Kandidaten \cite{sullivan_securing_2020, weibel_round_2020}.

Für digitale Signaturen wurde mit CRYSTALS-Dilithium ein weiteres Verfahren aus der CRYSTALS-Familie standardisiert. Dilithium basiert auf der kombinatorischen Härte des Short Integer Solution (SIS)- und des Module-LWE-Problems und verwendet das Fiat-Shamir with Aborts-Paradigma. Ein wesentliches Designziel ist die einfache und sichere Implementierbarkeit, insbesondere durch Verzicht auf zustandsbehaftete Operationen und durch Nutzung gleichmäßig verteilter Zufallswerte anstelle diskreter Gauss-Verteilungen, die als anfällig gegenüber Seitenkanalangriffen gelten (dilithium paper S. 3–5). Die Signaturen werden entweder deterministisch oder randomisiert erzeugt; Letzteres erhöht die Sicherheit in adversen Umgebungen, in denen Seitenkanalangriffe drohen. Zur Performanceoptimierung sind Implementierungen mit AVX2- und AES-Unterstützung verfügbar, die deutliche Geschwindigkeitsvorteile gegenüber Referenzimplementierungen zeigen (dilithium paper S. 8–9). Die Sicherheitsnachweise erfolgen sowohl im klassischen Random-Oracle-Modell (ROM) als auch im Quantum-ROM (QROM) unter Annahme der Härte der Module-LWE- und SIS-Probleme \cite[S. 6-7]{schwabe_dilithium_nodate}.

Das Verfahren SPHINCS+ verfolgt im Gegensatz zu Kyber und Dilithium einen hashbasierten Ansatz und setzt ausschließlich auf die Sicherheit kryptographischer Hashfunktionen. Dies ermöglicht ein besonders konservatives Sicherheitsmodell, das selbst unter Annahme fortgeschrittener algebraischer Quantenalgorithmen tragfähig bleibt \cite[s. 1-2]{schwabe_sphincs_2025}. Ein Alleinstellungsmerkmal von SPHINCS+ ist das stateless Design, welches im Gegensatz zu klassischen, zustandsbehafteten Hash-basierten Verfahren die Gefahr von Schlüsselverlusten durch fehlerhafte Zustandsverwaltung eliminiert. Die Signaturerzeugung basiert auf der Kombination mehrerer kryptographischer Bausteine, darunter Winternitz-One-Time-Signatures, Merkle-Bäume und HORST (eine Few-Time-Signature-Variante). Die daraus resultierenden Signaturen sind mit etwa 41 KB vergleichsweise groß, jedoch bieten sie hohe Sicherheit und Resistenz gegen eine breite Klasse von Angriffen, inklusive solcher unter Einbeziehung von Quantenrechnern \cite[S. 4-5]{schwabe_sphincs_2025}. Aufgrund dieser Eigenschaften empfiehlt sich SPHINCS+ insbesondere für Anwendungen mit langfristiger Vertrauenswürdigkeit, wie etwa Firmware-Signaturen oder die Verifikation kritischer Softwarekomponenten.

Die Auswahl und Standardisierung dieser Verfahren wurde von NIST sowohl unter Berücksichtigung mathematischer Sicherheitsannahmen als auch praktischer Implementierbarkeit und Performance getroffen. Insbesondere wurde ein Augenmerk auf Diversität der zugrundeliegenden Problemklassen gelegt, um im Sinne der Kryptoagilität eine robuste Sicherheitsarchitektur gegenüber zukünftigen algorithmischen Durchbrüchen zu gewährleisten \cite[S. 4, 9]{alagic_status_2025}. CRYSTALS-Kyber und CRYSTALS-Dilithium basieren auf Gitterproblemen, während SPHINCS+ auf die Sicherheit von Hashfunktionen setzt.

Die ausgewählten Algorithmen sind mittlerweile Bestandteil offizieller NIST-Standards: CRYSTALS-Kyber als ML-KEM in FIPS 203, CRYSTALS-Dilithium als ML-DSA in FIPS 204 und SPHINCS+ als SLH-DSA in FIPS 205. Erste industrielle Anwendungen und Pilotprojekte zeigen eine zunehmende Integration in sicherheitskritische Kommunikationsprotokolle und Cloud-Infrastrukturen \cite{alagic_status_2025, sullivan_securing_2020, weibel_round_2020}. Insgesamt stellt die NIST-Standardisierung eines der zentralen Anwendungsprojekte im Bereich PQK dar und liefert eine belastbare Grundlage für die künftige Migration kryptographischer Systeme in das Post-Quantum-Zeitalter.

\subsubsection{Quantum-Key-Distribution}

Die Quantum Key Distribution (QKD) stellt eine der derzeit technologisch am weitesten entwickelten Anwendungen der Quantenkommunikation dar. Ihr Ziel ist die abhörsichere Verteilung kryptographischer Schlüssel basierend auf quantenmechanischen Prinzipien. Aufgrund fundamentaler physikalischer Eigenschaften erlaubt QKD die Erkennung von Abhörversuchen und bietet damit in bestimmten Szenarien informationstheoretische Sicherheit. Dennoch bestehen Herausforderungen hinsichtlich Reichweite, Infrastrukturkosten und Interoperabilität mit bestehenden Kommunikationssystemen. Zwei bedeutende internationale Anwendungsprojekte verdeutlichen die verschiedenen strategischen Ansätze im Umgang mit diesen Herausforderungen: das chinesische Satellitenprogramm um den Micius-Satelliten sowie die europäische EuroQCI-Initiative.

Im Jahr 2016 startete China mit dem Satelliten \cite{courtland_chinas_2016} das erste operative Weltraumexperiment zur quantenmechanischen Schlüsselverteilung \cite{courtland_chinas_2016}. Der in einer Umlaufbahn von ca. 500~km operierende LEO-Satellit demonstrierte die Realisierbarkeit satellitengestützter QKD zwischen weit entfernten Bodenstationen und legte damit den Grundstein für eine globale Quantenkommunikationsarchitektur \cite{wang_modeling_2021}. Im Vergleich zu optischen Glasfaserverbindungen, deren Reichweite durch Dämpfung und Fehlerraten physikalisch limitiert ist, ermöglicht die freie Ausbreitung im Vakuum des Alls verlustärmere Verbindungen über mehrere tausend Kilometer.

Parallel zur Satellitenentwicklung wurde ein nationales QKD-Netz realisiert, das sich von Beijing bis Shanghai über ca. 2000~km erstreckt und 32 terrestrische Knoten umfasst, die als trusted nodes operieren \cite{wang_modeling_2021}. Diese Architektur wirft jedoch grundlegende Fragen hinsichtlich Vertrauen und Skalierbarkeit auf, da kompromittierte Knoten die Gesamtsicherheit untergraben können. Obwohl sie aus technologischer Sicht einfacher zu realisieren sind als quantenmechanische Repeater, bleibt ihre Eignung für hochsichere Anwendungen begrenzt. Aus diesem Grund rückt in China zunehmend die Entwicklung von Satellitenkonstellationen mit Inter-Satellite-Links (ISLs) in den Fokus, die eine redundante und dynamisch steuerbare Verteilung von Schlüsseln ermöglichen sollen \cite{wang_modeling_2021}.

Die Europäische Union verfolgt mit der EuroQCI den Aufbau einer sicheren paneuropäischen Quantenkommunikationsarchitektur. Ziel ist ein hybrides Netz, das terrestrische QKD-Übertragungen über Glasfaser mit satellitengestützten Komponenten kombiniert \cite{noauthor_european_2020}. Die Initiative umfasst dabei sowohl nationale Quanten-Backbones als auch grenzüberschreitende Knoten und wird in enger Kooperation mit der European Space Agency (ESA) umgesetzt.

Ein zentrales Teilprojekt ist der Satellit \cite{noauthor_eagle-1_2025}, der ab 2024 getestet werden soll. Das Vorhaben zielt auf die Demonstration von QKD via Satellit im Kontext europäischer Sicherheitsinfrastrukturen und wurde speziell auf regulatorische und industrielle Bedarfe innerhalb der EU abgestimmt (eagle1). Im Gegensatz zum chinesischen Micius-Satelliten handelt es sich bei Eagle-1 explizit um ein technologievalidierendes Pilotprojekt, das vor allem Schnittstellen und Interoperabilität mit terrestrischen Netzen erprobt.

Erste Systemdesignstudien wurden unter anderem vom Institut de Ciències Fotòniques (ICFO) in Spanien koordiniert und adressieren die technischen Herausforderungen von Synchronisation, Detektion und Netzwerkmanagement im Kontext von Low Earth Orbit Systemen \cite{van_deventer_towards_2022}. Ein interessantes Detail ist die geplante Modularität des EuroQCI-Systems, das eine sukzessive Erweiterung über Mitgliedsstaaten hinweg vorsieht, statt eine zentralistische Netzarchitektur zu forcieren.

Im direkten Vergleich zeigt sich, dass China auf Demonstrationen mit operationellem Charakter und nationaler Souveränität fokussiert, während die europäischen Aktivitäten stärker kooperativ, regulativ eingebettet und netzarchitektonisch offen angelegt sind. Beide Strategien erscheinen unter ihren jeweiligen geopolitischen und technologischen Rahmenbedingungen plausibel. Eine kritische Reflexion muss jedoch auch die langfristige Wartbarkeit, Standardisierung und Kostenstruktur berücksichtigen. Gerade hier wird sich zeigen, ob der europäische Ansatz mit seiner Betonung auf Interoperabilität und systemischer Integration über den Prototypenstatus hinaus skaliert werden kann.

\subsubsection{Quantum-Random-Number-Generator}

Während großskalige Quantenkommunikationssysteme wie QKD-Netzwerke in der Regel erhebliche infrastrukturelle Investitionen und spezifische physikalische Rahmenbedingungen erfordern, lassen sich Komponenten wie Quantum Random Number Generators (QRNG) bereits heute in einer Vielzahl bestehender Systeme integrieren. QRNG fungiert dabei als grundlegende Bausteintechnologie in kryptographischen Anwendungen, indem es echte, nicht-deterministische Zufallszahlen auf Basis quantenmechanischer Prozesse erzeugt. Die Kommerzialisierung dieser Technologie erfolgt primär in Form eigenständiger Hardware-Module oder integrierbarer Chips, die sich durch geprüfte Entropiequellen, regulatorische Konformität und standardisierte Schnittstellen auszeichnen. Im Folgenden werden vier aktuelle Anwendungsprojekte vorgestellt, die unterschiedliche Implementierungsstrategien, Zielmärkte und technologischen Reifegrade illustrieren.

ID Quantique entwickelt seit mehreren Jahren miniaturisierte QRNG-Chips, die sich insbesondere für eingebettete Systeme, mobile Endgeräte und IoT-Infrastrukturen eignen. Die Quantis-QRNG-Chips basieren auf der quantenmechanischen Messung von Schussrauschen eines lichtempfindlichen Elements. Konkret wird dabei ein Verstärkerschaltkreis zur Erfassung der Quantenfluktuationen eines Photodetektors verwendet, aus denen durch nachgeschaltete Entropieextraktion bitweise Zufallsdaten generiert werden \cite{noauthor_quantis_2025}. Die verwendeten Verfahren stellen sicher, dass die erzeugten Bits nicht durch klassische Prozesse vorherbestimmt oder rekonstruierbar sind. Ziel ist eine kontinuierliche, rückführbare und stromsparende Generierung echter Zufallszahlen in Anwendungen, bei denen weder hohe Datenraten noch externe optische Komponenten verfügbar sind – etwa in Secure Elements oder als Entropiequelle in Embedded Devices. Die Chips sind für industrielle Zertifizierungsprozesse vorbereitet und werden mittlerweile in verschiedenen Mobilplattformen evaluiert, beispielsweise in vernetzten Fahrzeugkomponenten und sicherheitskritischen Sensornetzwerken.

Ein zentraler Treiber für die Akzeptanz und Skalierbarkeit von QRNG ist die Standardisierung der zugrundeliegenden Technologien. Im Rahmen des ETSI Industry Specification Group QKD arbeitet ein Konsortium unter Beteiligung von ID Quantique an der Formulierung technischer Spezifikationen für QRNG-Systeme. Die aktuelle Spezifikation GS QKD 014 legt Kriterien zur Charakterisierung von QRNG-Komponenten fest, insbesondere hinsichtlich Modellierung der quantenmechanischen Entropiequelle, Entropieextraktion, Testbarkeit und Systemarchitektur \cite{curran_idq_2023}. Zusätzlich wird zwischen „strong quantum“, „quantum-origin“, und „pseudo-random“ unterschieden, je nachdem, ob die Zufallsquelle rein quantenbasiert, hybrid oder deterministisch ist \cite{van_deventer_towards_2022}. Diese Kategorisierung dient nicht nur der Interoperabilität, sondern adressiert auch die Zertifizierbarkeit und Sicherheitsklassifikation in kritischen Infrastrukturen. Die ETSI-Initiative schlägt darüber hinaus vor, QRNGs künftig als definierte Komponenten in Public Key Infrastructures (PKI) zu integrieren, etwa zur Schlüsselinitialisierung oder als Seed für deterministische Algorithmen in hybriden Kryptosystemen.

Die von Toshiba entwickelte USB-QRNG-Serie richtet sich an Anwendungen in professionellen Desktop- und Rechenzentrumsumgebungen. Die Geräte nutzen eine optische Methode, bei der einzelne Photonen auf einen Strahlteiler gelenkt und anschließend detektiert werden. Die Entscheidung, ob ein Photon auf Detektor A oder B trifft, basiert auf fundamentaler Quantenunsicherheit, wodurch Bitfolgen mit maximaler Entropie erzeugt werden \cite{toshiba_europe_cambridge_research_laboratory_quantum_2025}. Der Vorteil dieser Architektur liegt in der unmittelbaren physikalischen Rückführbarkeit der Zufälligkeit sowie in der einfachen Integration über eine standardisierte USB-Schnittstelle. Die Bitraten liegen im Bereich einiger Mbit/s und eignen sich damit sowohl zur Initialisierung kryptographischer Prozesse (z.B. RSA-Schlüsselerzeugung, TLS-Handshakes) als auch als Entropiequelle für Betriebssysteme oder Sicherheitsmodule. Toshiba hebt besonders die Resistenz gegenüber externen Einflussgrößen hervor, da die Detektion in einem abgeschirmten optischen System erfolgt. Die Geräte wurden unter anderem in der britischen Post-Quantum-Initiative evaluiert und werden derzeit auch in Kombination mit PQC-Algorithmen getestet.

Ein umfassender Überblick über aktuelle und potenzielle QRNG-Anwendungen findet sich im Bericht „QRNG Report 2021“ von evolutionQ. Dort wird deutlich, dass sich die Einsatzfelder weit über klassische Kryptographie hinaus erstrecken. QRNG wird beispielsweise in der Tokenisierung von Finanztransaktionen, bei der Erzeugung von Seeds für Blockchain-Schlüsselpaare oder in der Protokollinitialisierung sicherer Multi-Party-Computing-Systeme eingesetzt \cite{??????} <- Piani et al. Besonders hervorgehoben wird die Rolle von QRNG in virtualisierten und containerisierten Cloud-Infrastrukturen, bei denen klassische Entropiequellen wie /dev/random nicht hinreichend isoliert oder manipulationssicher sind. QRNG kann hier als dedizierter Hardware-Entropieprovider über PCIe, USB oder Netzwerkprotokolle eingebunden werden. Ein weiteres Anwendungsfeld ist die Verwendung in sicherheitskritischer Hardware wie Hardware Security Modules (HSMs), wo QRNG zur Generierung nicht reproduzierbarer Einmalschlüssel beiträgt. Laut evolutionQ liegt der entscheidende Vorteil in der messbaren Entropieherkunft, die sowohl regulatorischen Anforderungen (z.B. eIDAS, FIPS) als auch zukünftigen Anforderungen an Post-Quantum-Resilienz gerecht wird.

Die vorgestellten Anwendungsprojekte zeigen, dass QRNG nicht mehr als isolierte Labortechnologie zu betrachten ist, sondern sich zunehmend als integraler Bestandteil moderner Sicherheitsarchitekturen etabliert. Während sich einzelne Implementierungen – etwa in Form von USB-Geräten oder Chips – technisch stark unterscheiden, eint sie das Ziel, vertrauenswürdige und physikalisch nachvollziehbare Zufallsquellen für kryptographische Kernfunktionen bereitzustellen. In der Gesamtschau ergibt sich ein technologieoffenes, aber klar sicherheitsgetriebenes Innovationsfeld: QRNG schließt eine zentrale Lücke in der Kette quantensicherer Systeme, indem es nicht nur den algorithmischen Teil, sondern auch die zugrunde liegende Entropiequelle absichert. Damit kommt dieser Technologie eine Schlüsselrolle im Übergang von klassischen zu postquantenresilienten Sicherheitsinfrastrukturen zu – und zwar nicht nur auf konzeptioneller, sondern bereits auf operativer Ebene.

\subsection{Fazit}
%Zusammenfassung:

%Bewertung des Standes:

%Zukunftsausblick:

%Fazit/Abschluss:

\printbibliography
