%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Anwendung in der Chemie \& Materialforschung}
\label{trends} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

\chapterauthor{Hüma Yilmaz, Sabine Weigand}

\abstract{some abstract}

\section{Relevanz \& Problemstellung}
{Ein fundiertes Verständnis quantenmechanischer Prozesse ist entscheidend für Fortschritte in der Chemie und Materialwissenschaft (vgl. \cite{hanaor_computational_2024}, \cite{daley_practical_2022}, \cite{bauer_quantum_2020}). Klassische Simulationsmethoden wie die Dichtefunktionaltheorie (DFT), Hartree-Fock oder kraftfeldbasierte Molekulardynamik vereinfachen das Verhalten von Elektronen, um es rechnerisch behandelbar zu machen. Zwar lassen sich damit viele Eigenschaften von Atomen, Molekülen und Festkörpern zuverlässig beschreiben, doch bei komplexen elektronischen Systemen, insbesondere mit stark korrelierten Elektronenzuständen oder Übergangsmetallen, stoßen sie an methodische und rechnerische Grenzen (vgl. \cite{daley_practical_2022},\cite{vermaStatusChallengesDensity2020}, \cite{cao_quantum_2019}) \newline\newline
Klassische Methoden zeigen Schwächen bei der Erfassung statischer Korrelation, elektronischer Verschränkung und Van-der-Waals-Kräfte. Hinzu kommen typische Fehler wie die Überdelokalisierung von Elektronendichten oder Selbstwechselwirkungen. Auch chemische Reaktionen, die mit Bindungsbrüchen oder Ladungstransfer einhergehen, lassen sich mit kraftfeldbasierten Ansätzen kaum realistisch modellieren. Exakte quantenmechanische Verfahren bieten zwar höhere Genauigkeit, ihr Rechenaufwand wächst jedoch exponentiell mit der Systemgröße, was ihre Anwendung auf größere Moleküle oder Materialien stark einschränkt (vgl. \cite{vermaStatusChallengesDensity2020}, \cite{cao_quantum_2019}).
\newline\newline
Quantencomputer bieten hier eine Chance. Da sie selbst auf quantenmechanischen Prinzipien basieren, können sie elektronische Eigenschaften von Molekülen und Festkörpern deutlich realistischer abbilden (vgl. \cite{bauer_quantum_2020}, \cite{akromDevelopmentQuantumMachine2024}). Besonders vorteilhaft ist ihre Fähigkeit, Multireferenz-Zustände zu beschreiben, die für die präzise Modellierung von Spin-Kopplungen, Ladungstransfer und Reaktionsdynamik erforderlich sind (vgl. \cite{akromDevelopmentQuantumMachine2024}).
Hybride quantenklassische Algorithmen wie der Variational Quantum Eigensolver (VQE) oder die Quantum Phase Estimation (QPE) ermöglichen bereits heute die Berechnung elektronischer Grund- und Anregungszustände mit hoher Genauigkeit (vgl. \cite{aspuru-guzik_simulated_2005}, \cite{weidman_quantum_2024}, \cite{cao_quantum_2019}). Dabei werden klassische Optimierungsverfahren mit quantenmechanischen Zustandsvorbereitungen kombiniert, um die begrenzten Ressourcen aktueller Quantencomputer effizient zu nutzen.\newline\newline
Die Verbindung von Quanteninformationstheorie und moderner Quantenchemie führt zu neuartigen algorithmischen Ansätzen, die nicht nur bestehende Methoden verbessern, sondern neue Zugänge zur physikalischen Realität eröffnen (vgl. \cite{liu_quantum_2020}, \cite{weidman_quantum_2024}). Damit erschließen Quantencomputer neue Forschungsräume, die mit klassischen Simulationsverfahren bislang unzugänglich waren.}


\section{Top 3 Anwendungsfelder}
{Quantencomputer eröffnen neue Perspektiven für zentrale Fragestellungen in der Chemie und Materialwissenschaft. In dieser Arbeit stehen drei Anwendungsfelder im Fokus: die Simulation von Molekülen, Materialforschung am Beispiel Batterien und die Modellierung elektronischer Korrelationen und Defekte in Festkörpern.
Diese Auswahl basiert auf drei Kriterien. Erstens besitzen alle drei Bereiche hohe praktische Bedeutung, etwa in der Energiewende, der Entwicklung neuer Katalysatoren und der Halbleitertechnologie. Zweitens stoßen klassische Simulationsmethoden in diesen Bereichen an Grenzen, da viele Prozesse durch stark korrelierte Elektronen, Multireferenzzustände, Defekte oder nichtlineare Dynamiken geprägt sind, die mit herkömmlichen Verfahren nur unzureichend erfasst werden können. Drittens gibt es in allen drei Feldern eine aktive Forschungsgemeinschaft und konkrete Projekte, die Quantenalgorithmen erproben und weiterentwickeln.}

\subsection{Simulation von Molekülen}
{Die Simulation von Molekülen und chemischen Reaktionen ist ein zentrales Anwendungsfeld des Quantencomputings in der Chemie. Klassische Computer stoßen hierbei schnell an ihre Grenzen, da der Rechenaufwand zur Lösung der Schrödinger-Gleichung mit der Anzahl der Teilchen exponentiell ansteigt. Besonders bei größeren Molekülen oder Elektronensystemen mit starker Wechselwirkung werden etablierte Verfahren wie Hartree-Fock oder die Dichtefunktionaltheorie (DFT) entweder zu ungenau oder zu rechenintensiv (vgl. \cite{bauer_quantum_2020}).}

\subsubsection{Historische Motivation und Grundidee}
{Richard Feynman und Yuri Manin erkannten bereits in den 1980er Jahren, dass Quantencomputer die natürliche Komplexität quantenmechanischer Systeme effizient modellieren können. Quantencomputer werden dafür genutzt, quantenmechanische Phänomene wie Superposition und Verschränkung abzubilden. So lassen sich die komplexen Zustände von Molekülen und chemischen Reaktionen realistischer und effizienter darstellen (vgl. \cite{feynmanSimulatingPhysicsComputers1982}).}


\subsubsection{Verständnis und Vorhersage von Reaktionsmechanismen}

Ein zentrales Ziel in der chemischen Forschung ist das detaillierte Verständnis von Reaktionsmechanismen . Übergangszustände, Energiebarrieren und Reaktionspfade bestimmen, wie schnell und selektiv eine Reaktion abläuft. Quantencomputer bieten die Möglichkeit, mehrdimensionale Potenzialflächen vollständig zu simulieren, ohne auf vereinfachte Näherungen beschränkt zu sein. Dadurch können präzisere Aussagen über Aktivierungsenergien und Effekte wie kinetische Isotopieverschiebungen getroffen werden, was beispielsweise die Entwicklung effizienterer Katalysatoren und neuer Synthesewege unterstützt (vgl. \cite{liu_quantum_2020}, \cite{mcardle_quantum_2020}).

\subsubsection{Untersuchung elektronischer Strukturen und ihrer Dynamik}
Moleküle, besonders solche mit Übergangsmetallen oder ungepaarten Elektronen, besitzen komplexe Elektronenstrukturen. Klassische Methoden wie die Dichtefunktionaltheorie (DFT) stoßen hier an ihre Grenzen, da sie nur einen stark vereinfachten elektronischen Zustand berücksichtigen und viele quantenmechanische Effekte wie Elektronenkorrelationen oder Verschränkung nicht korrekt erfassen (vgl. \cite{weidman_quantum_2024}). Quantencomputer hingegen können diese Multireferenz-Zustände direkt darstellen und ermöglichen so eine detailliertere Modellierung von Spin-Kopplungen, Ladungstransfer-Prozessen oder Verschränkungsphänomenen im Elektronengas (vgl. \cite{bauer_quantum_2020}, \cite{mcardle_quantum_2020}).

\subsubsection{Simulation von Moleküldynamik (Time Evolution) und Reaktionsverläufen}


Chemische Reaktionen verlaufen auf eine Weise, bei der während des Ablaufs sowohl die Elektronenverteilung als auch die Bewegung der Atomkerne gleichzeitig und aufeinander abgestimmt verändert werden. Das ist besonders in der Photochemie der Fall, wenn Licht eine Reaktion auslöst und dabei elektronische und strukturelle Änderungen eng miteinander verflochten sind. Herkömmliche Ansätze verwenden oft Surfacehopping-Approximationen (vgl. \cite{barbattiNonadiabaticDynamicsTrajectory2011}), um zwischen potenziellen Energieflächen zu wechseln. Quantenalgorithmen hingegen ermöglichen die direkte Simulation der zeitlichen Entwicklung (time evolution) des molekularen Quantenzustands (vgl. \cite{bauer_quantum_2020}). Dadurch lassen sich Reaktionskinetiken, kurzlebige Zwischenzustände und elektronische Übergänge vorhersagen, beispielsweise zur Interpretation ultrakurzer spektroskopischer Signale.
In der Praxis wird diese Methode eingesetzt, um die Mechanismen der Singulettspaltung in organischen Halbleitermaterialien zu entschlüsseln, was einen wichtigen Beitrag zur Effizienzsteigerung moderner Solarzellen leistet (vgl. \cite{motlagh_quantum_2025}, \cite{baldacchino_singlet_2022}). Ein weiteres Anwendungsfeld ist die Analyse lichtinduzierter Prozesse in der Biochemie, wie dem Sehvorgang oder der Photosynthese, bei denen quantencomputergestützte Simulationen dazu beitragen, elektronische Anregungen und molekulare Strukturänderungen in Echtzeit aufzuklären (vgl. \cite{macdonell_predicting_2023}).


\subsection{Materialforschung anhand von Batterien}

Die Entwicklung und Optimierung von Batteriematerialien stellt eine zentrale Herausforderung der modernen Materialwissenschaft dar. Batterien sind hochkomplexe Vielteilchensysteme, in denen quantenmechanische Effekte auf atomaren Längen- und Femtosekunden-Zeitskalen überlagert zusammenspielen und unmittelbaren Einfluss auf Abschlussprozesse wie Ionentransport, Lade-/Entlade-Kinetiken und Grenzflächenbildung nehmen (vgl. \cite{bauer_quantum_2020}). Klassische Ansätze stoßen rasch an ihre Grenzen, weil sie die feingliedrigen elektronischen Wechselwirkungen nur näherungsweise abbilden können – dies limitiert unser Verständnis, wie Atome und Moleküle in Elektroden und Elektrolyten „miteinander kommunizieren“ und damit die Batterie-Performance langfristig einschränken (vgl. \cite{demirApplicationQuantumComputing2024}).
Aktuell dominieren Lithium-basierte Materialien den Markt, doch ihre Stabilität und Kapazität nehmen mit zunehmender Zyklenzahl ab, sodass Alternativen (z. B. Natrium-, Magnesium- oder Calcium-Batterien) dringend erforscht werden müssen (vgl. \cite{demirApplicationQuantumComputing2024}). Hinzu kommen externe Faktoren wie hohe Betriebstemperaturen oder hohe Lade-/Entladeströme, die Materialdegradation und unerwünschte Nebenreaktionen beschleunigen. Gerade im Kontext der Energiewende sind leistungsfähige, langlebige und umweltverträgliche Batteriesysteme ein Schlüssel für den flächendeckenden Einsatz erneuerbarer Energien.

Quantum Computing eröffnet hier neue Perspektiven: Durch die nativ quantenmechanische Beschreibung von Elektronen- und Ionenbewegungen lassen sich komplexe Wechselwirkungen und Grenzflächenprozesse auf atomarer Ebene präzise simulieren. Dies ermöglicht tiefere Einsichten in fundamentale Mechanismen wie Ladungstransfer, Redoxreaktionen und die Bildung stabiler Solid-Electrolyte-Interphasen, die mit klassischen Methoden nur unzureichend abgebildet werden können (vgl. \cite{bauer_quantum_2020}, \cite{demirApplicationQuantumComputing2024}).


\subsubsection{Berechnung von Gleichgewichtszellspannungen und Redoxpotentialen}
Die Gleichgewichtszellspannung E∘ einer elektrochemischen Zelle beschreibt die im Ruhezustand messbare Spannung zwischen Anode und Kathode. Sie ergibt sich aus der Differenz der Redoxpotentiale, die angeben, wie leicht eine Substanz Elektronen aufnimmt oder abgibt. Mit quantenmechanischen Methoden lassen sich Zellspannungen und Redoxpotentiale vorab berechnen, um neue Elektrodenmaterialien gezielt zu bewerten. Ein praktisches Beispiel ist die Berechnung der Zellspannung in Lithium-Ionen-Batterien, etwa für verschiedene Kathodenmaterialien wie LiCoO₂, um die Energiedichte und Leistungsfähigkeit neuer Batterien schon vor der Synthese vorherzusagen (vgl. \cite{urban_computational_2016}, \cite{hanaor_computational_2024}).

\subsubsection{Simulation von Ionenmobilität und Diffusionskoeffizienten}
Die Beweglichkeit von Ionen ist ein wesentlicher Faktor für die Ladegeschwindigkeit und Effizienz moderner Batterien. Damit Ionen wie Lithium oder Natrium während des Lade- und Entladevorgangs schnell und verlustarm durch das Elektrodenmaterial wandern können, müssen sie Energiebarrieren überwinden. Mithilfe quantenmechanischer Simulationen lassen sich diese Barrieren sowie die Diffusionskoeffizienten, also die Geschwindigkeit der Ionenbewegung im Festkörper, präzise auf atomarer Ebene berechnen (vgl. \cite{hanaor_computational_2024}, \cite{urban_computational_2016}). Quantenalgorithmen ermöglichen hierbei eine realistische Abbildung der elektronischen Struktur und der Wechselwirkungen im Material, wodurch der Einfluss verschiedener Kristallstrukturen quantitativ erfasst werden kann(( vgl. \cite{aspuru-guzik_simulated_2005}, \cite{baker_simulating_2024}).
Diese Simulationen sind in der Materialentwicklung unverzichtbar, um elektrodenspezifische Ionentransportwege zu identifizieren und zu optimieren. Beispielsweise werden Kathodenmaterialien wie LiCoO₂ oder neuartige Festelektrolyte hinsichtlich ihrer Ionenmobilität systematisch untersucht. Solche Erkenntnisse unterstützen die Entwicklung von Batterien, die sowohl schnelle Ladeprozesse als auch eine lange Lebensdauer gewährleisten (vgl. \cite{hanaor_computational_2024}, \cite{urban_computational_2016}).

\subsubsection{Dynamische Prozesse: SEI-Bildung und Elektrolyt-Zersetzung (Time Evolution)}
Quantencomputer können die zeitliche Entwicklung chemischer Reaktionen (time evolution) direkt simulieren. So lassen sich beispielsweise die Ausbildung der SEI-Schicht an der Anode – ein Prozess, der innerhalb von Sekunden bis Minuten erfolgt – oder die schrittweise Zersetzung von Elektrolyten detailliert nachvollziehen (vgl. \cite{hanaor_computational_2024}). Der Einfluss des Hamilton-Operators auf solche Reaktionen ist mit klassischen Methoden nur schwer zu erfassen, während Quantenalgorithmen diese Prozesse effizient und atomgenau beschreiben können (vgl. \cite{weidman_quantum_2024}). Besonders leistungsfähig ist hier die auf quantenmechanischen Prinzipien basierende atomistische Molekulardynamik (AIMD), die Bindungsbildung und -bruch realistisch abbildet. Dadurch lassen sich wertvolle Einblicke in Mechanismen der Batteriealterung, Ionenmobilität und chemischen Stabilität gewinnen (vgl. \cite{hanaor_computational_2024}, \cite{weidman_quantum_2024}).

\subsection{Elektronenkorrelation und Defektmodellierung in der Festkörperchemie}
Die Modellierung von Defekten in Festkörpern, durch Leerstellen, Zwischengitteratomen oder Dotierungen, gehört zu einem der wichtigsten und zugleich schwierigsten Themen der modernen Materialforschung. Ideale Kristalle selten und Abweichungen von der perfekten Gitterstruktur beeinflussen zentrale Eigenschaften wie Leitfähigkeit, Magnetismus, optische Absorption und mechanische Stabilität. Besonders in Halbleitern, Supraleitern oder Quantenmaterialien wie topologischen Isolatoren sind Defekte entscheidend für die Funktion des gesamten Systems (vgl. \cite{bassett_quantum_2019}).
Klassische Simulationen sind bei solchen Aufgaben oft unzureichend, da stark lokalisierte Elektronenzustände oder Spin-Zustände rund um Defektstellen nur ungenau beschrieben werden können (vgl. \cite{bauer_quantum_2020}). Gerade wenn mehrere Elektronenkonfigurationen gleichzeitig berücksichtigt werden müssen (Multireferenzcharakter), stoßen klassische Verfahren an ihre Grenzen (vgl. \cite{bassett_quantum_2019}).
Quantencomputer bieten hier neue Möglichkeiten, da sie stark korrelierte Vielteilchensysteme direkt auf Basis quantenmechanischer Prinzipien modellieren können (vgl. \cite{daley_practical_2022}).

\subsubsection{Stark korrelierte Materialien und Hochtemperatur-Supraleitung}

Stark korrelierte Materialien und Hochtemperatur-Supraleiter sind zentrale Forschungsgebiete, die ohne die Einbeziehung von Elektronenkorrelationen kaum verstanden werden könnten. Theoretisch beschäftigt man sich mit der Frage, wie kollektive Phänomene wie der Mott-Übergang, Spin-Ladungs-Entkopplung oder unkonventionelle Supraleitung aus der Wechselwirkung zahlreicher Elektronen hervorgehen (vgl.\cite{daley_practical_2022}). Traditionelle Methoden wie Hartree-Fock oder die Standard-DFT sind hier oft nicht ausreichend, weshalb weiterentwickelte Ansätze wie die Dynamische Mean-Field-Theorie (DMFT) oder Multi-Referenz-Methoden angewendet werden. Inzwischen ermöglichen Quantencomputer und Quantensimulatoren die realitätsnahe Modellierung dieser Systeme, indem sie die komplexen Vielteilchenzustände ab-initio behandeln können (vgl. \cite{baker_simulating_2024}).
In der Praxis haben Experimentalphysiker mit Hilfe analoger Quantensimulatoren, etwa auf Basis ultrakalter Atome, erstmals den Mott-Übergang im Fermi-Hubbard-Modell nachgestellt (vgl. \cite{daley_practical_2022}). Auch die Quantensimulation von antiferromagnetischen Phasenübergängen in Festkörpern wurde erfolgreich umgesetzt. Ebenso werden heute auf Quantenprozessoren mit optimierten Algorithmen wie dem Variational Quantum Eigensolver (VQE) neue Einsichten in die elektronischen Strukturen korrelierter Systeme gewonnen, was konkrete Impulse für das Materialdesign etwa von Hochtemperatur-Supraleitern liefert (vgl. \cite{weidman_quantum_2024}).

\subsubsection{Punktdefekte und Dotierungen in Halbleitern}

In Halbleitern sind Punktdefekte wie Leerstellen, Zwischengitteratome oder gezielte Dotierungen essenziell für grundlegende Eigenschaften wie Leitfähigkeit, Ladungsträgerdichte und optische Aktivitäten (vgl.\cite{bassett_quantum_2019}). Theoretisch wird dazu etwa die energetische Lage von Defektzuständen im Bandabstand oder die Wechselwirkung mit freien Ladungsträgern untersucht (vgl. \cite{freysoldt_first-principles_2014}). Klassische DFT-Ansätze unterschätzen meist die Bandlücke und beschreiben lokal gebundene Elektronenzustände bei Defektstellen oft nur ungenau. Quantencomputing eröffnet hier neue Wege, indem Defektbildungsenergien, Ladungsniveaus und sogar Diffusionsbarrieren auf ab-initio-Niveau bestimmt werden können (vgl. \cite{bassett_quantum_2019}).
Praktisch wurden mit hybriden Quantenalgorithmen bereits Simulationen von Farbzentren in Diamant oder Stickstoff-Leerstellen in Siliziumcarbid durchgeführt. Dies sind beides Systeme, die als Quantensensoren oder als Bauelemente für Quantencomputer zum Einsatz kommen könnten  (vgl. \cite{baker_simulating_2024}, \cite{cao_ab_2023}). Durch Quantensimulation lässt sich beispielsweise der Aufbau von Spin-Zuständen oder die Dynamik von Elektron-Loch-Paaren experimentell überprüfen und gezielt optimieren, was direkt in neue optoelektronische oder quantentechnologische Anwendungen einfließt (vgl. \cite{cao_ab_2023}).

\subsubsection{Defektmechanismen in Batteriematerialien}

Die Funktion von Batteriematerialien basiert auf der Bewegung von Ionen, die stets mit Defektbildungen wie Leerstellen oder Interkalationszentren verknüpft ist. In der Theorie werden dabei die elektronischen Zustände von Defekten und ihre Wechselwirkung mit mobilen Ionen untersucht, insbesondere wenn stark korrelierte Übergangsmetallionen beteiligt sind (vgl. \cite{hanaor_computational_2024}, \cite{freysoldt_first-principles_2014}). Klassische Berechnungsmethoden kommen dabei oft an ihre Grenzen, weil sie gemischte Ladungszustände oder komplexe chemische Reaktionen nicht genau erfassen können. Quantencomputer können dagegen die komplizierten elektronischen Strukturen und auch dynamische Vorgänge wie die Bewegung der Ionen, die Bildung von Schutzschichten (SEI) oder Phasenübergänge besser simulieren (vgl. \cite{urban_computational_2016}).
In der Praxis entwickeln Forschungsgruppen Quantenalgorithmen zur präzisen Berechnung der Redoxzustände und defektassoziierten Mechanismen. Erste Anwendungen zeigen, dass so wichtige Kenngrößen wie Zellspannung, Stabilität und Lebensdauer von Energiematerialien sehr viel realitätsnäher vorhergesagt werden können (vgl. \cite{baker_simulating_2024}). Dies eröffnet neue Perspektiven für das gezielte Design von Kathodenmaterialien und die Erhöhung der Energiedichte und Lebensdauer moderner Batterien (vgl. \cite{hanaor_computational_2024}).



\section{Top Technologien \& Algorithmen}
In der Entwicklung quantenbasierter Verfahren zur Lösung komplexer Probleme haben sich in den letzten Jahren verschiedene vielversprechende Ansätze etabliert. Insbesondere hybride Algorithmen, die Quanten- und klassische Rechenmethoden kombinieren, spielen dabei eine zentrale Rolle. Sie nutzen das Potenzial von Quantencomputern für spezielle Aufgaben, wie die präzise Bestimmung von Energiezuständen in Molekülen oder die effiziente Lösung kombinatorischer Optimierungsprobleme, und ergänzen diese durch bewährte klassische Optimierungsverfahren.
\vspace{1em}
Dieses Kapitel stellt drei zentrale Vertreter solcher Technologien vor: Variational Quantum Algorithms (VQAs), die Quantum Phase Estimation (QPE) sowie den Quantum Approximate Optimization Algorithm (QAOA). Dabei werden sowohl deren Funktionsweise als auch ihre Anwendungsmöglichkeiten in der Chemie und Materialforschung und Grenzen näher beleuchtet.



\subsubsection*{Variational Quantum Algorithms}
{Variational Quantum Algorithms (VQAs) sind eine Methode, um mit Quantencomputern die Energiezustände eines physikalischen Systems, beispielsweise eines Moleküls, zu berechnen. Es handelt sich hierbei um ein hybrides Verfahren, bei dem sowohl Quantencomputer als auch herkömmliche Computer genutzt werden, um ein klassisches Optimierungsverfahren auszuführen \citealp[6]{weidmanQuantumComputingChemistry2024a}.
Es gibt dabei zwei Haupttypen von VQAs, zwischen denen zu differenzieren ist: Variational Quantum Simulation (VQS) und Variational Quantum Optimization (VQO). VQS simulieren dynamische Prozesse, indem sie die zeitliche Entwicklung in einem abstrakten Raum möglichst akkurat nachbilden. VQO dagegen streben danach, Zielzustände zu finden, indem sie eine sogenannte Kostenfunktion minimieren \citealp[23]{mottaEmergingQuantumComputing2022}.

Konkret finden VQO Bedeutung in der Chemie unter anderem als Variational Quantum Eigensolver (VQE). Dieser VQE-Algorithmus wurde zur Bestimmung der Grundzustandsenergie elektronischer Moleküle entwickelt. Dafür wird zunächst eine angenommene Form der Elektronenverteilung, der sogenannten Wellenfunktion, für ein Molekül gewählt. Der Quantencomputer berechnet den Erwartungswert der Energie eines Systems für bestimmte Parameter (E(θ)) \citealp[23]{mottaEmergingQuantumComputing2022}, woraufhin der klassische Computer die Parameter dieser Wellenfunktion so anpasst, dass die berechnete Energie immer kleiner wird. Dieser Ablauf wird so lange wiederholt, bis die geringste mögliche Energie ermittelt wird und somit die Grundzustandsenergie des elektronischen Moleküls geschätzt werden kann \citealp[6]{weidmanQuantumComputingChemistry2024a}.
Diese statistische Schätzung ergibt sich als Durchschnittswert mit einer gewissen Streuung. Deshalb müssen die Optimierungsverfahren, die die Parameter schrittweise verbessern, darauf achten, dass diese Messwerte nicht exakt, sondern mit Unsicherheit behaftet sind \citealp[23]{mottaEmergingQuantumComputing2022}.
Dieser VQE-Algorithmus wurde auch auf andere Bereiche ausgeweitet, etwa Lösungsverfahren für lineare Gleichungssysteme, Matrixzerlegung und numerische lineare Algebra \citealp[6]{weidmanQuantumComputingChemistry2024a}.
ABSATZ
Bei dem VQE-Verfahren sind die Messfehler statistisch klar abschätzbar, allerdings bleibt dennoch eine gewisse Unsicherheit in der geschätzten elektronischen Energie bestehen. Um diese Fehler zu verringern, müsste der verwendete Ansatz (die Wellenfunktion) verbessert werden. Dafür wären allerdings deutlich mehr Quantenoperationen nötig, als heutige Quantencomputer ohne Fehlerkorrektur ausführen können. Aus diesem Grund sollte alternativ die Quantum Phase Estimation (QPE) betrachtet werden \citealp[7]{vonburgQuantumComputingEnhanced2021}.}



\subsubsection*{Quantum Phase Estimation}
Quantum Phase Estimation (QPE) ist ein grundlegender Quantum-Algorithmus, mit dem sich die Eigenenergie eines Quantensystems präzise bestimmen lässt. In der Quantenchemie wurde bereits 2005 mit dem QPE die Energie eines Moleküls in einer Simulation ermittelt \citealp[5]{weidmanQuantumComputingChemistry2024a}. Der Algorithmus kann den möglichst niedrigen Energiezustand direkt identifizieren, wenn ein geeigneter Startzustand verwendet wird. Je öfter die zentrale Quantenoperation wiederholt wird, desto genauer wird das Ergebnis.
Die Durchführung der Methode sieht die Vorbereitung von zwei Qubit-Registern vor, eines für das Molekül (Systemregister) und eines für die Messung (Hilfsregister). Das Hilfsregister wird mithilfe sogenannter Hadamard-Operationen in eine Überlagerung gebracht, sodass es viele mögliche Phasen gleichzeitig abbilden kann. Diese Vorbereitung ermöglicht es, die Energieinformation als Phase im späteren Verlauf präzise auszulesen \citealp[25]{weidmanQuantumComputingChemistry2024a}, \citealp[29]{mottaEmergingQuantumComputing2022}. 

Das Quantensystem wird so weiterentwickelt, dass die Energie als Phase im Hilfsregister gespeichert wird. Dazu sorgt jedes Hilfs-Qubit dafür, dass das System für eine bestimmte Zeit weiterläuft. Wenn das System eine bestimmte Energie hat, sammelt das Hilfsregister bei jeder Zeitentwicklung einen passenden Phasenwert. Um diese im Hilfsregister gespeicherten Phaseninformationen in eine konkrete Energieangabe zu überführen, wird eine inverse Quanten-Fourier-Transformation angewendet. Dieser Schritt sorgt dafür, dass sich die zuvor aufgebauten Phasen zu einem klaren Interferenzmuster überlagern. Dadurch entsteht ein charakteristisches Signal, aus dem die Energie des Systems als Bitfolge abgelesen werden kann \citealp[7]{vonburgQuantumComputingEnhanced2021}, \citealp[25]{mottaEmergingQuantumComputing2022}. Im letzten Schritt wird das Hilfsregister gemessen. Wenn der Systemzustand zu Beginn bereits ein reiner Eigenzustand des Hamiltonoperators ist, liefert die Messung exakt die zugehörige Energie – ohne statistische Schwankungen. Dies ist die sogenannte Zero-Variance-Eigenschaft. Wenn der Startzustand jedoch eine Mischung verschiedener Eigenzustände war, projiziert die Messung das System zufällig auf einen dieser Zustände. Die Wahrscheinlichkeit, mit der ein bestimmter Energiewert dabei herauskommt, ist davon abhängig, wie stark der Anfangszustand mit dem jeweiligen Eigenzustand übereinstimmt. Wird dieser Vorgang mehrfach wiederholt oder der Startzustand gezielt gewählt, so kann die gewünschte Energie zuverlässig ermittelt werden \citealp[7]{vonburgQuantumComputingEnhanced2021},\citealp[25]{mottaEmergingQuantumComputing2022}.
Ein Nachteil ist allerdings, dass QPE eine deutlich komplexere und längere Quantenberechnung erfordert. Deshalb ist sie auf zukünftige, fehlerkorrigierte Quantencomputer angewiesen. Doch im Gegensatz zu Methoden wie VQE, bei denen immer eine gewisse Unsicherheit bleibt, liefert QPE exakte und kontrollierbare Ergebnisse, sobald die Hardware leistungsfähig genug ist \citealp[7]{vonburgQuantumComputingEnhanced2021},\citealp[25]{mottaEmergingQuantumComputing2022}.



\subsubsection*{Quantum Approximate Optimization Algorithm}
Neben diesen Verfahren zur präzisen oder variativen Bestimmung von Energiezuständen gibt es weitere hybride Algorithmen, die speziell für Optimierungsaufgaben konzipiert wurden. Ein besonders vielversprechender Vertreter ist der Quantum Approximate Optimization Algorithm (QAOA), der sich für kombinatorische Probleme eignet und zunehmend auch in der Chemie und Materialforschung Anwendung findet.
QAOA gehört zur Familie dieser hybriden Variationsverfahren und wurde speziell für kombinatorische Optimierungsprobleme entwickelt, wodurch die optimalen Lösungen schneller ermittelt werden, als es durch brute force möglich wäre \citealp[3]{guoHarnessingQuantumPower2024}. Das Problem wird durch einen sogenannten Kosten-Hamiltonian beschrieben. Dies ist ein Operator, der jeder möglichen Lösung einen Energiezustand zuweist, wobei die Lösung dem niedrigsten Energiezustand entspricht \citealp[24]{mottaEmergingQuantumComputing2022}, \citealp[8]{guoHarnessingQuantumPower2024}. Ergänzt wird dieser durch einen sogenannten Mixer-Hamiltonian, der das System kontrolliert aus dem Startzustand in verschiedene Konfigurationen lenkt. Der Algorithmus führt anschließend abwechselnd beide Operatoren für bestimmte Zeitspannen aus, wobei die Parameter dieser Zeitspannen durch klassische Optimierung angepasst werden. Diese basieren auf wiederholten Messungen und der Bewertung der Ergebnisqualität \citealp[8]{guoHarnessingQuantumPower2024}.
Diese Kombination von quantenmechanischer Zustandserzeugung und klassischer Rückkopplung ermöglicht es, gute Lösungen effizient zu finden, ohne den gesamten Lösungsraum durchsuchen zu müssen. Mit steigender Anzahl der Schichten (p-Level) im Raum wird die Lösungsqualität besser, allerdings steigt hiermit auch die Anforderung an die Hardware.
In der Materialwissenschaft wurde QAOA bereits in Simulationen zur Gestaltung von Metamaterialien eingesetzt. Dabei wurde ein Quantenannealing-Modell genutzt, um transparente Kühlbeschichtungen mit optimierter Energieeffizienz zu entwerfen \citealp[18]{guoHarnessingQuantumPower2024}. Währenddessen zeigen sich in der Chemie Anwendungsmöglichkeiten in der molekularen Wirkstoffsuche, wie durch Optimierung molekularer Strukturen im Hinblick auf ihre Bindungsstärke. Guo et al. (2024) demonstrierten dies mit einem quantengestützten Verfahren, das verschiedene zweiatomige Moleküle auf ihre Bindungsstärke an eine Protein-Tasche untersuchte. Die aktuell erhältliche Hardware ist allerdings begrenzt und schränkt die Anwendungsmöglichkeiten ein. Herausforderungen wie Rauschunempfindlichkeit und das Barren-Plateau-Problem müssen jedoch noch überwunden werden \citealp[12]{weidmanQuantumComputingChemistry2024a}.


\section{Top 3 Zukunftsprojekte \& Forschungsinitiativen}

In diesem Kapitel werden drei herausragende Initiativen vorgestellt, die maßgeblich zur Weiterentwicklung des Quantencomputings beitragen. Sie stehen exemplarisch für unterschiedliche institutionelle und strategische Ansätze, mit denen Wissenschaft, Industrie und Politik den Weg zur praktischen Nutzung der Quanteninformationstechnologie gestalten. 

\subsubsection*{PASQuanS2 – EU-Flaggschiff-Initiative}
PASQuanS2 – EU-Flaggschiff-Initiative für Quantum Simulation
Das europäische „Quantum Flagship“ ist eine der drei großen Forschungsinitiativen der EU und verfolgt das Ziel, Europa als zentrale Kraft in der zweiten Quantenrevolution zu etablieren und eine wettbewerbsfähige Quantenindustrie aufzubauen \citealp[1]{r} \cite{}(Riedel et al., 2019), S. 1). Mit einem Budget von rund einer Milliarde Euro über zehn Jahre konzentriert sich das Programm auf vier zentrale Technologiefelder: Quantenkommunikation, -computing, -simulation sowie -sensorik und -metrologie \cite{}(Riedel et al., 2017), S. 3).
Ein koordiniertes europäisches Vorgehen wurde notwendig, da es an standardisierten Schnittstellen, klaren Verwertungsstrategien und langfristigen industriellen Partnerschaften mangelte \cite{}((Riedel et al., 2019), S. 2; \citealp[2ff.]{}(Räsänen, 2021), S. 2–3). Einen entscheidenden politischen Impuls lieferte das 2016 veröffentlichte „Quantum Manifesto“, das die Quantenforschung als strategische Schlüsseltechnologie zur Sicherung digitaler Souveränität definierte \citealp[1]{vandeventerEuropeanStandardsQuantum2022}. Um die Interoperabilität der Systeme und deren Skalierbarkeit zu gewährleisten, gilt die Entwicklung gemeinsamer technischer Standards als entscheidender Schritt. Auch wenn laut \citealp[2ff.]{vandeventerEuropeanStandardsQuantum2022} bislang noch keine übergreifende Standardisierungsstrategie existiert, arbeiten Initiativen wie das Quantum Industry Consortium (QuIC) sowie mehrere Arbeitsgruppen des Quantum Flagship aktiv daran, regulatorische und technische Rahmenbedingungen europaweit zu harmonisieren. Auf dieser Grundlage entstand eine strategische Forschungsagenda, die technologische Meilensteine definiert und sowohl Grundlagenforschung als auch industriellen Transfer miteinander verzahnt \cite{}((Riedel et al., 2019), S. 3). Im Folgenden werden zentrale technische Umsetzungsansätze und konkrete Forschungsprojekte innerhalb des Quantum Flagship näher beleuchtet.
Ein herausragendes Beispiel dafür ist das Projekt PASQuanS2 (Programmable Atomic Large-Scale Quantum Simulation), das im Rahmen des Flagships finanziert wird. Ziel von PASQuanS2 ist die Entwicklung hochskalierbarer, programmierbarer Quantensimulatoren auf Basis ultrakalter Atome und Ionen, um realitätsnahe Vielteilchenprobleme effizient berechnen zu können \cite{}((Räsänen, 2021), S. 6ff.). Die aktuelle Projektphase PASQuanS2.1 (2023–2026) fokussiert auf Plattformen mit mindestens 2.000 steuerbaren Quantenteilchen und legt damit die Grundlage für spätere Systeme mit bis zu 10.000 Teilchen. 
PASQuanS2 stützt sich technologisch auf drei sich ergänzende Plattformstrategien, die jeweils unterschiedliche physikalische Prinzipien nutzen. Die erste basiert auf Neutralatom-Arrays in optischen Gittern, bei denen ultrakalte Atome mithilfe von Lasern in regelmäßigen Strukturen angeordnet werden. Die zweite Plattform nutzt sogenannte optische Pinzetten (Tweezers-Systeme), in denen einzelne Atome präzise fixiert und über kontrollierte Rydberg-Wechselwirkungen miteinander gekoppelt werden. Die dritte Strategie setzt auf Ionenfallenarchitekturen, bei denen geladene Teilchen in elektromagnetischen Feldern eingeschlossen und durch kollektive Schwingungen miteinander verbunden werden. Jede dieser Technologien bringt unterschiedliche Stärken hinsichtlich Skalierbarkeit, Stabilität und Kopplungspräzision mit sich, verfolgt jedoch das gemeinsame Ziel, quantenmechanische Vielteilchendynamiken experimentell zugänglich zu machen. \cite{}(PASQuanS2 - Transforming the Landscape for Programmable Quantum Simulation in Europe | PASQuanS 2, o. J.) Ein zentraler technischer Fokus liegt auf der Erhöhung der Zustandsfidelity auf unter \(0{,}1\,\%\), der Verbesserung von Lese- und Schreibprozessen sowie der Entwicklung verlässlicher Messprotokolle wie Randomized Benchmarking oder Hamiltonian Learning zur Validierung der Simulationsergebnisse. Gleichzeitig wird an modularen Softwareschnittstellen gearbeitet, um eine einfache Integration der Hardware in bestehende IT-Infrastrukturen und Cloud-Umgebungen zu ermöglichen. Dadurch sollen industrielle und wissenschaftliche Anwendergruppen ohne tiefergehende Hardwarekenntnisse Zugang zu den Quantensimulatoren erhalten – ein entscheidender Schritt in Richtung praktischer Nutzbarkeit. \cite{}((Räsänen, 2021), S. 6ff.)
Das Forschungsprojekt PASQuanS2 verdeutlicht exemplarisch, wie das europäische Quantum Flagship wissenschaftlichen Fortschritt gezielt mit technologischer Skalierbarkeit und wirtschaftlicher Verwertbarkeit zu verknüpfen versucht. Es verkörpert den strategischen Anspruch Europas, sich durch ein föderiertes, konsensorientiertes Innovationsmodell gegenüber international stark subventionierten Programmen in den USA und China langfristig wettbewerbsfähig aufzustellen \citealp[7ff.]{vogiatzoglouEUsQuestDigital2025}.
 

\subsubsection*{IBM Quantum & Qiskit Nature} 
IBM (International Business Machines Corporation) zählt zu den traditionsreichsten Technologieunternehmen weltweit und hat die Entwicklung der Informatik über Jahrzehnte maßgeblich mitgestaltet, beispielsweise durch den Mainframe, relationale Datenbanken oder IBM Watson \cite{aruteQuantumSupremacyUsing2019a}. Nun positioniert sich IBM als treibende Kraft im Quantencomputing. Mit der Initiative IBM Quantum verfolgt das Unternehmen das Ziel, skalierbare Quantenhardware zu entwickeln, über die Cloud zugänglich zu machen und durch das Open-Source-Framework Qiskit auch für Forschung und Industrie nutzbar zu gestalten \cite{} (Akash & Jamema, 2025.\cite{miceliQuantumComputationVisualization2018}. 
IBM Quantum bezeichnet IBMs industrielle Quanten-Computing-Initiative, die sowohl modernste Quantenhardware als auch Cloud-Zugriff für Forschung und Industrie bereitstellt. Bereits 2016 stellte IBM den ersten frei zugänglichen Quantencomputer über die IBM Quantum Experience in der Cloud zur Verfügung. Dies bildete die Grundlage für eine breit angelegte Forschungsinfrastruktur. Dies zeigt sich zu Beginn des Jahres 2024, wobei mehr als drei Billionen Quantenoperationen über IBMs Quanten-Cloud durchgeführt und rund 2.800 wissenschaftliche Arbeiten unter Verwendung von IBM-Quantenprozessoren veröffentlicht wurden. IBM hat sich damit als führender Akteur etabliert und adressiert ein breites Anwendungsspektrum von quantenchemischen Simulationen und Optimierungsproblemen bis hin zu Kryptographie und Machine Learning. Gleichzeitig treibt IBM die Hardware-Entwicklung voran. Dies zeigt sich 2023 mit der Vorstellung von „Condor“, ein supraleitender Quantenchip mit 1.121 Qubits, nachdem bereits 2021/22 die Prozessoren „Eagle“ (127 Qubits) und „Osprey“ (433 Qubits) technische Meilensteine gesetzt hatten. Diese enge Verzahnung von Forschungs-Initiative und zugänglicher Infrastruktur macht IBM Quantum zu einer zentralen Plattform für Quantencomputing-Fortschritte \citealp[2]{abughanemIBMQuantumComputers2025}.
Ein essenzieller Bestandteil von IBM Quantum ist das Open-Source-Software-Framework Qiskit, das 2017 von IBM veröffentlicht wurde. Qiskit stellt ein umfangreiches Software Development Kit (SDK) für Quantencomputing bereit und hat sich zum meistgenutzten Werkzeug dieser Art entwickelt. Es bietet eine benutzerfreundliche API zur Konstruktion von Quanten-Schaltkreisen und automatisiert die nötigen Schritte, um diese auf echter Quantenhardware auszuführen. Konkret definiert das Qiskit-„Patterns“-Modell einen strukturierten Workflow in vier Schritten. Zuallererst wird das ursprüngliche Problem in einen Quanten-Schaltkreis übersetzt. Anschließend wird diese Schaltung mittels Transpilation optimiert und an die Ziel-Hardware angepasst. Folgend wird der Schaltkreis auf einem ausgewählten Quantenprozessor (oder Simulator) ausgeführt und abschließend werden die Resultate ausgelesen und klassisch nachverarbeitet \citealp[7]{abughanemIBMQuantumComputers2025}. Dieses Cloud-basierte Toolchain-Konzept ermöglicht es Nutzern, Quantenprogramme nahtlos vom Laptop bis auf die supraleitenden IBM-Quanten-Prozessoren zu bringen. Über Qiskit können Berechnungen entweder auf hochleistungsfähigen Simulatoren oder direkt auf den realen IBM-Quantencomputern in der Cloud durchgeführt werden. IBM stellt dafür mehrere Quantenprozessoren mit über IBM Quantum Experience frei zur Verfügung, zugänglich über ein webbasiertes Interface, welches insbesondere den Einstieg für eine breite Nutzerschaft erleichtert \citealp[5]{wangAdvantagesTwoQuantum2025}. Die robuste Hardware in Verbindung mit einer nahtlos integrierten Software-Umgebung hat wesentlich dazu beigetragen, dass bereits Millionen von Experimenten mithilfe von Qiskit auf IBM-Systemen durchgeführt wurden. Damit zählt IBM zu den zentralen Akteuren in der praktischen Umsetzung und Skalierung von Quantencomputing-Anwendungen weltweit.
Der hohe Praxisbezug von IBM Quantum zeigt sich insbesondere in der gezielten Anwendung wissenschaftlicher Algorithmen auf reale Problemstellungen. Ein zentrales Anwendungsfeld ist dabei die Quantenchemie, in der klassische Rechner schnell an ihre Grenzen stoßen. Hier kommen hybride Quantenalgorithmen wie der Variational Quantum Eigensolver zum Einsatz, der bereits im vorherigen Unterkapitel ausführlich behandelt wurde. \citealp[5]{}.((Miceli & McGuigan, 2018) vgl. S.5) IBM’s Software-“Stack” unterstützt solche hybriden Ansätze mit spezialisierten Bibliotheken, wie Qiskit Nature (früher als Qiskit Chemistry bekannt). Dies ist ein Open-Source-Framework, das quantenmechanische Probleme aus den Naturwissenschaften, insbesondere in der Chemie, im Computer abbildet. Qiskit Nature stellt Funktionen bereit, um elektronische Strukturen von Molekülen in Form der Zweiten Quantisierung zu formulieren und an Quantenalgorithmen zu koppeln. So können klassische Quantenchemie-Programme für Vorabrechnungen integriert werden. Beispielsweise lässt sich ein Hartree-Fock-Grundzustand mit etablierten Programmpaketen berechnen und an Qiskit übergeben. Darauf aufbauend kommen quantum-classical Algorithmen wie VQE zum Einsatz, um die Korrektur zur Hartree-Fock-Lösung zu bestimmen. Typischerweise wird dabei ein Unitary Coupled Cluster-Ansatz mit Einfach- und Doppelanregungen (UCCSD) verwendet, der vom Hartree-Fock-Zustand ausgeht. \citealp[2ff.]{avramidisGroundStateProperty2024}.
Die Leistungsfähigkeit und Herausforderungen dieses Ansatzes werden in aktuellen Forschungsarbeiten deutlich. So wurden 2024 erstmals die Grundzustands-Eigenschaften mehrerer Lithiumhydrid-Komplexe (LiH, LiH2, LiH3 samt ihren Ionen) vollständig mit Qiskit und dem VQE-Algorithmus simuliert. Dabei diente ein UCCSD-Ansatz als quantenchemische Wavefunction, und es wurden neben den Grundzustandsenergien auch Elektronenaffinitäten, Ionisierungsenergien und Dipolmomente der Moleküle berechnet. Die Ergebnisse zeigen, dass VQE in der Lage ist, die elektronischen Grundzustandsgrößen dieser einfachen Moleküle mit hoher Genauigkeit zu reproduzieren \citealp[4]{avramidisGroundStateProperty2024}.
Zusammenfassend bildet IBM Quantum mit seinem ganzheitlichen Ansatz, von der leistungsfähigen Hardware über das umfangreiche Qiskit-Softwarepaket bis hin zu spezialisierten Modulen wie Qiskit Nature, eine zukunftsweisende Forschungsplattform. Als eines der “Top Zukunftsprojekte” treibt IBM Quantum damit sowohl die Weiterentwicklung der Quantencomputing-Technologie als auch deren Anwendung in wissenschaftlichen und industriellen Domänen maßgeblich voran.

\subsubsection*{Google Quantum AI & Sycamore} 
Googles Quantenforschungseinheit, Quantum AI, ist eine ambitionierte privatwirtschaftliche Initiative im Bereich der Quanteninformationsverarbeitung.  Eingebettet in die Alphabet-Struktur verfolgt Google einen Full-Stack-Ansatz. Dabei werden alle Ebenen der Quantencomputer-Architektur intern entwickelt. Dies umfasst die Hardware, darunter supraleitende Qubits und Quantenchips. Auch die Steuer- und Ausleseelektronik wird intern entwickelt. Hinzu kommen Softwarekomponenten wie Compiler, Fehlerkorrekturverfahren und das Open-Source-Framework Cirq, mit dem sich Quantenalgorithmen programmieren lassen. Im Mittelpunkt steht der 2019 vorgestellte Sycamore-Prozessor, ein supraleitender Quantenchip mit 53 funktionsfähigen Transmon-Qubits, der auf einem zweidimensionalen Gitter basiert \cite{aruteQuantumSupremacyUsing2019a}.
Der zentrale Durchbruch gelingt Google mit der Demonstration der Quantenüberlegenheit (quantum supremacy). Es ist definiert als die Fähigkeit eines Quantencomputers, eine spezifische Rechenaufgabe schneller zu lösen als jeder bekannte klassische Computer. Konkret ließ Google seinen Sycamore-Prozessor eine Zufalls-Sampling-Aufgabe ausführen, bei der bitstring-Ausgaben aus tiefen, pseudozufälligen Quanten-Schaltkreisen generiert wurden. Diese Aufgabe wurde in 200 Sekunden bewältigt. Im Vergleich dazu hätte ein klassischer Supercomputer wie Summit für dieselbe Aufgabe laut Google rund 10.000 Jahre benötigt \cite{aruteQuantumSupremacyUsing2019a}. Dieses Ergebnis wurde über die sogenannte Cross-Entropy Benchmarking (XEB)-Fidelity mit einem Wert von ca. 0.002 validiert \cite{}(Akash & Jamema, 2025). Dies weist darauf hin, dass die gemessenen Ausgaben signifikant von gleichverteilten Zufallswerten abweichen und somit mit den theoretisch erwarteten Quantenverteilungen übereinstimmen.
IBM, als direkter Wettbewerber im Bereich supraleitender Qubits, widersprach dieser Interpretation und argumentierte, dass sich dieselbe Sampling-Aufgabe durch Optimierungen klassischer Algorithmen und Einsatz von Massenspeicher innerhalb von 2,5 Tagen auf klassischen Maschinen lösen ließe \cite{}. (Pednault et al., 2019). Diese Diskussion verursachte nicht nur technische, sondern auch begriffliche Spannungen, wobei IBM den Begriff „Quantenüberlegenheit“ als irreführend kritisiert und stattdessen quantum advantage als neutraleren Ausdruck vorschlug (IBM Quantum Blog, 2019). Ungeachtet der Debatte bleibt Sycamore ein technologischer Meilenstein. Die auf dem Chip eingesetzten sogenannten Sycamore-Gates sind eine spezielle Form von fSim-Gates. Das ist eine Kombination aus rotationssymmetrischen iSWAP-Operationen und kontrollierten Phasenverschiebungen, die hohe Verschränkung bei gleichzeitig reduzierter Fehlerrate ermöglichen \cite{abughanemPhotonicQuantumComputers2024}. Die durchschnittliche Die Fehlerquote beträgt bei simultaner Ausführung \(0{,}93\,\%\) für Zwei-Qubit-Gates und \(3{,}8\,\%\) bei der Auslesung \cite{}(Arute et al., 2019).
Im Anschluss an das Supremacy-Experiment rückten Forschungsfragen zur Fehlertoleranz, Skalierbarkeit und plattformübergreifenden Vergleichbarkeit in den Vordergrund. Einen bemerkenswerten Beitrag dazu leistet die Studie von AbuGhanem & Eleuch (2024), die eine vollständige Quantenprozess- und Zustandstomographie des Sycamore-Gates auf IBMs Quantencomputern durchführten. Die Autoren untersuchten dabei nicht nur Simulationen unter idealen und verrauschten Bedingungen, sondern führten die Messungen auch auf echter IBM-Quantenhardware durch. Die Ergebnisse zeigten auf IBMs Plattform zeigte eine Prozessfidelity von \(81{,}02\,\%\). Dieser Wert liegt nahe an dem, was unter realen Bedingungen auf aktueller Hardware technisch erreichbar ist, und zeigt, dass Sycamore-Gates auch auf einer konkurrierenden Architektur wie der von IBM mit hoher Qualität implementiert werden können \cite{}(AbuGhanem, 2025).
Solche herstellerübergreifenden Analysen sind wegweisend: Sie ermöglichen nicht nur Benchmarks für Gate-Qualitäten unter realistischen Bedingungen, sondern fördern auch eine Standardisierung der Metriken zur Bewertung von Quantencomputern \cite{abughanemPhotonicQuantumComputers2024}. Die Kombination aus hoher Gate-Qualität, tiefer Architekturkenntnis und öffentlich zugänglicher Software macht Google Quantum AI zu einem der Treiber des Fortschritts auf dem Weg zur praktischen Nutzung von Quantencomputern. Langfristig fokussiert sich Google auf die Umsetzung eines fehlertoleranten, skalierbaren Quantencomputers mit Anwendungen in Chemie, Optimierung und KI \cite{}. (Butt et al., 2024).
Damit steht Google Quantum AI mit Sycamore exemplarisch für den Übergang von wissenschaftlichen Demonstrationen hin zu strategisch nutzbaren Quantentechnologien. Dies hat erheblichen Implikationen für Forschung, Industrie und sicherheitskritische IT-Systeme.


\section{Bewertung anhand der Kriterien}
\section{Teilfazit}


\printbibliography
