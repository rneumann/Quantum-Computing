%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Ethische Aspekte}
\label{ethics} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

\chapterauthor{Halima Albader Alhusini, Gizem Bulut, Adrian Hußfeldt Vazquez, Tayebeh Nazari}

\abstract{Kurzfassung des Kapitels}

\section{Ethik-Grundlagen}

Die schnelle Entwicklung des Quantencomputings wirft weitreichende Fragen auf, die rein über technische oder ökonomische Fragestellungen hinausgehen. Als disruptive Technologie hat QC das Potenzial, die globale Kommunikation, Sicherheitsmechanismen, politische und gesellschaftliche Machtverhältnisse sowie viele weitere Aspekte grundlegend zu verändern. Die potenziell weitreichenden Auswirkungen erfordern eine sorgfältige Auseinandersetzung auch mit ethischen Prinzipien und Maßstäben, um den Einsatz von QC auch mit gesellschaftlichen Werten in Einklang zu bringen. Ethik fungiert dabei als normativer Kompass: Sie zeigt nicht nur technische Potenziale auf, sondern auch, was moralisch erstrebenswert ist, und wo moralisch Risiken liegen. Gerade im Kontext des Quantencomputings, dessen langfristige Folgen aktuell noch schwer abzuschätzen sind, ist es von Bedeutung, geeignete ethische Ansätze zu identifizieren und diese bereits in der Entwicklung solcher Technologien anzuwenden. Ein Beispiel für die frühe Entwicklung ethischer Leitlinien und deren Bedeutung wird beim Thema künstliche Intelligenz deutlich. So hat die EU beispielsweise bereits im Jahr 2019 durch Fachexperten der Technikethik ethische Leitlinien für vertrauenswürdige KI entwickeln lassen. \cite{}
(Quelle: Ethics guidelines for trustworthy AI) 
\\
\\
In diesem Kapitel werden zunächst zentrale Ethiktherorien vorgestellt und Begriffe definiert. Aufbauend darauf wird in Kapitel 2 untersucht, welche Akteure (Stakeholder) im Quantencomputing entscheidend sind und wie Verantwortlichkeiten und Governance-Strukturen ausgestaltet werden. Im Anschluss werden in Kapitel 3  normative Spannungsfelder untersucht, in denen sich die Chancen und Risiken des Quantencomputings ergeben. Abschließend werden mögliche Gestaltungsoptionen diskutiert und ein Fazit gezogen, sowie ein weiterer Ausblick gegeben.

\subsection{Überblick über zentrale Ethiktheorien}

Es existieren unterschiedliche ethische Ansätze, die als Bewertungsrahmen für technologische Innovation herangezogen werden können. Dieser Abschnitt soll einen Überblick über ethische Grundmodelle im Bereich der Technikethik bieten, die zu unserer Thematik Anwendung finden können. In dieser Betrachtung werden die Kernelemente der jeweiligen Ethik betrachtet.

\subsubsection{Utilitarismus}
Der Utilitarismus ist Teil der konsequentialistischen Ethikansätze. Er geht zurück auf Philosophen wie Jeremy Bentham und John Stuart Mill und setzt das Prinzip der kollektiven Nutzenmaximierung aller Betroffenen ins Zentrum. Das Ziel ist demnach das größtmögliche Glück für die größtmögliche Zahl zu erzeugen. Die Folgen einer Handlung oder Innovation werden demnach bilanziell aufgestellt und aggregiert. Das Ziel besteht darin, das subjektive Wohlbefinden zu steigern. Der Utilitarismus fordert dabei auch ein Miteinbeziehen zukünftiger Generationen bei langfristigen Entscheidungen. Im Kontext von Technologien und Innovationen ist der Utilitarismus passend, da auch dieser häufig die Charakteristik der Maximierung der Nützlichkeit aufweist. Ebenfalls zeigt sich eine Ähnlichkeit in der utilitaristischen Ansicht, dass ein Eingriff in die Vorgabe der Natur zulässig ist, wenn eine technische Optimierung stattfindet. Es wird dabei rein auf die Folgen der "Optimierung" geachtet.  Jedoch existieren ebenfalls hier der Natur nähere "grüne"  Interpretationen des Utilitarismus, welche Demut, Achtsamkeit und kooperativität zur Erhaltung und Sicherung der Lebensgrundlagen als Kernelemente identifizieren. Bei der utilitaristischen Betrachtung technischer Entwicklungen müssen neben Chancen und Risiken auch Unsicherheit und Katastrophenpotenzial berücksichtigt werden. \cite{}
Quelle: Handbuch Technikethik, Seite 160 - 164

\subsubsection{Tugendethik}
Im Gegensatz zu den anderen großen Ethiktheorien (Deontologie und Konsequentialismus), bei welchen eher Handlungen im Mittelpunkt stehen, wendet sich die Tugendethik nicht den einzelnen Handlungen, sondern der Persönlichkeit der handelnden Person zu, also dem jeweiligen Träger der moralischen Verantwortung. Im Zentrum stehen dabei Tugenden, also bestimmte Haltungen eines moralischen Charakters, wie beispielsweise Klugheit (phronesis oder Verstandestugend), Mut und Gerechtigkeit, an welchen ein Mensch sein Handeln und Denken ausrichtet. Moralisches Handeln wird hierbei nicht als Pflicht angesehen, sondern als Ausdruck eines guten Charakters. Dieser entwickelt sich aus dem Studium des richtigen Handelns. Historisch hatte die Tugendethik, welche auf Aristoteles zurückgeht, ein tugendhaftes, also erfülltes Leben, zum Ziel. Im Kontext der Technologieentwicklung sind Ansätze erforderlich, um die Tugendethik in das Curriculum der Entwickler zu integrieren und technisches Wissen mit verantwortungsvollem Handeln in komplexen und unsicheren Situationen zu verknüpfen. Verbinden lässt sich dies, da technische Innovation meist ebenfalls eine Verbesserung des menschlichen Lebens zum Ziel hat. \cite{}
Quelle: Handbuch Technikethik, Seite 165 - 169


\subsubsection{Deontologie}
Die Deontologie gehört zu den bekanntesten und am weitesten verbreiteten ethischen Denkschulen. Einer ihrer bedeutendsten Vertreter und Begründer war Immanuel Kant. Über die Jahre hinweg haben sich in Bezug auf die Deontologie sowohl verschiedene Interpretationen als auch Definitionen ergeben, diese stehen zwar meist eng in Verbindung, sind allerdings nicht deckungsgleich. Im Vergleich zur Tugendethik steht bei der deontologischen Ethik nicht der Charakter des Handelnden, sondern die moralische Beurteilung der Handlung selbst im Vordergrund. Zentral ist die Vorstellung, dass bestimmte Handlungen aus Prinzip verboten oder geboten sind, unabhängig von den Konsequenzen. In der Ethik nach Kant bildet der kategorische Imperativ dabei den Kern: Jede Handlung muss so beschaffen sein, dass ihre zugrunde liegende Maxime als allgemeines Gesetz gelten kann. Damit weist Kant allen rationalen Subjekten universelle Pflichten zu, unabhängig davon, welchen Nutzen oder Schaden das konkrete Ergebnis dieser Handlung haben mag. Im Laufe des 20. Jahrhunderts wurde die kantische Pflichtethik in zahlreichen Varianten und Ergänzungen weiterentwickelt. In der Technikethik markiert die deontologische Perspektive einen grundsätzlichen Bruch mit rein zweck-mittelorientierten Entscheidungslogiken. Gemäß der Standarddefinition deontologischer Ethiken wird die moralische Richtigkeit technischer Handlungsoptionen nicht allein an ihrer Effizienz bei der Zielerreichung gemessen, sondern auch an Kriterien, die sich jeder reinen Nutzen- bzw. Risikoabwägung entziehen. So lassen sich Gerechtigkeitsüberlegungen zur Risikoverteilung oder Rechte wie beispielsweise das Recht auf Privatsphäre nicht einfach als Variable in eine Optimierung einbauen. Sie müssen vielmehr als vorrangige Normen gelten, die technische Lösungen einschränken. \cite{}
Quelle: Quelle: Handbuch Technikethik, Seite 171 - 174
pfleger, das gute Leben, Seite 94 - 101
Neuhäuser, handbuch angewandte ethik, Seite 67 - 73

\subsection{Ethische Chancen \& Risiken}

Im Zusammenhang mit Quantencomputing unterscheiden wir zwischen technologischen Potenzialen und ethischen Chancen. Technologische Potenziale beschreiben primär die funktionalen Möglichkeiten einer Technologie, beispielsweise in den Anwendungsfeldern der Kryptographie oder Medizintechnik. Andere Sichtweisen beziehen das technologische Potenzial auf die strategischen Möglichkeiten für Unternehmen. Ethische Chancen und darüber hinaus beziehen sich auf die positiven Beiträge, also den positiven Wert, den eine Technologie zum menschlichen Wohlergehen, zur sozialen Gerechtigkeit oder zur ökologischen Nachhaltigkeit leisten kann. Ein ethisch wertvolles Innovationsziel ist demnach nicht allein die technische Machbarkeit und die Erzielung von Profit, sondern auch die Stärkung gesellschaftlicher Werte wie Teilhabe, Solidarität und Langzeitgerechtigkeit. Im Unterschied zu reinem Fortschrittsoptimismus oder wirtschaftlichen Vorteilen fragt die Begriffsbestimmung ethischer Chancen explizit danach, welche gesellschaftlichen Werte durch eine Technologie gefördert werden und wie diese Förderung über die eigentliche Funktionalität hinausgeht. Aus ethischer Perspektive gilt ein Fortschritt erst dann als Chance, wenn er nicht nur Profit generiert, sondern auch den kollektiven Nutzen in Form von Sicherheit, Gesundheit oder Umweltintegrität und weiteren Aspekten messbar erhöht. In diesem Sinne entspricht unsere Auffassung und Definition von ethischen Chancen in dieser Arbeit dem Ansatz der utilitaristischen Technikethik, die welchem aggregierten gesellschaftlichen Nutzen in den Mittelpunkt stellt. \cite{} Quelle: Hofer et al. Potential Based technology (technisches Potential); Ethische chance/wert: Brusoni und Vaccaro (Ethics, Technology ...) und Bednar (The Power of Ethics...)
\\
\\
Ethische Risiken erfassen potenzielle Schäden, die über rein technische Fehlfunktionen oder betriebswirtschaftliche Verluste hinausgehen und gesellschaftliche Werte wie Autonomie oder Gerechtigkeit nachteilig für die Mehrheit beeinflussen. Im Kontext der künstlichen Intelligenz definieren Douglas et al. (2024, S. 1 ff.) ethische Risiken als „jedes mit einer KI verbundene Risiko, das dazu führen kann, dass die Beteiligten eine oder mehrere ihrer ethischen Verpflichtungen gegenüber anderen Beteiligten verletzen.“ Angesichts der vergleichbaren potenziellen Disruptivität und Reichweite der Technologie lässt sich diese Definition direkt auf das Quantencomputing übertragen. Demnach umfasst das ethische Risiko des Quantencomputings alle (ethisch) negativen Folgen, die durch dessen Einsatz für die verschiedenen Stakeholder – von Nutzern über Entwickler bis hin zu Betroffenen Dritten – entstehen können. Hierzu zählen beispielsweise Dual-Use oder der zukünftige Zugang zu Quantentechnologie. Diese Definition bietet ebenfalls, wie die ethischen Chancen, eine Ähnlichkeit mit der utilitaristischen Sichtweise der Technikethik und der Betrachtung des möglichen aggregierten "Leids", welches durch die Technologie oder deren Nutzung für die Stakeholder hervorgeht. \cite{} Quelle: Ethical risk for AI (Douglas et al.)
\\
\\
Die ethischen Chancen und Risiken werden im Rahmen dieser Arbeit in Abschnitt 3 „Normative Spannungsfelder” in Bezug auf das Quantencomputing näher betrachtet. Dabei werden verschiedene Anwendungen und Spannungsfelder hinsichtlich ihrer ethischen Risiken und Chancen analysiert.


\subsection{Verantwortung}
In der Angewandten Ethik ist die Verantwortung ein Grundbegriff. Einerseits dient er dazu, zu klären, welche Akteure überhaupt als moralische Subjekte gelten können. Andererseits beschreibt er, wie abstrakte Rechte und Pflichten konkret auf Handelnde verteilt werden. Gerade in Anwendungsfeldern wie der Umwelt- oder Medizinethik oder im Bereich grundlegender technologischer Innovationen geht es immer wieder darum, wer welche Pflichten trägt und wofür diesbezüglich Rechenschaft abzulegen ist. Im Bereich der Ethik lässt sich die Verantwortung meist als dreistellige Relation darstellen mit den zentralen Fragestellungen: (1) Wer ist verantwortlich? (2) Wofür ist jemand verantwortlich? (3) Wem gegenüber wird die Verantwortung getragen? Diese Struktur ermöglicht es, die Komplexität von Verantwortungszuschreibungen abzubilden, während zugleich die Übersichtlichkeit erhalten bleibt. Zur ersten Frage „Wer ist verantwortlich?” – wird zwischen allgemeiner Verantwortungsfähigkeit und konkreter Verantwortungszuschreibung unterschieden. Verantwortungsfähig sind nur Akteure, die \textbf{willensfrei}, \textbf{handlungsfähig} sind und einen \textbf{moralischen Standpunkt einnehmen} können. Erst auf dieser Grundlage kann in einer konkreten Situation Verantwortung zugeschrieben werden. Bezüglich konkreter Verantwortung wird diese zugeschrieben, wenn eine Person sich der Verantwortung freiwillig bekennt, ihr die Verantwortung automatisch zufällt (z. B. wenn der diensthabende Notarzt in der Notaufnahme automatisch die Verantwortung für die Versorgung eines bewusstlosen Patienten übernimmt) oder diese zugewiesen wird. Die zweite zentrale Fragestellung nach dem "Wofür jemand verantwortlich ist" differenziert zwischen \textbf{haftender Verantwortung} für bereits eingetretene Folgen eigener Handlungen und \textbf{sorgender Verantwortung} für künftige Ereignisse oder ihre Abschätzung. Haftende Verantwortung bezieht sich auf die eigenen Handlungen und deren Folgen. Die sorgende Verantwortung hingegen fordert präventives, aktives Eingreifen, um mögliche Schäden abzuwenden oder zu mindern, auch wenn der Schaden nicht auf das eigene Handeln zurückgeht, sondern auf andere Personen oder natürliche Vorgänge. Zur dritten zentralen Fragestellung bezüglich wem gegenüber die Verantwortung getragen wird. Hierbei kann eine Verantwortung einerseits gegenüber anderen Personen entstehen oder gegenüber bestimmter normativer (Werte-)Maßstäbe (Recht, moralische Verantwortung). Die Verantwortung gegenüber Personen oder spezifischen Gruppen umfasst beispielsweise Patientinnen und Patienten, deren Angehörige, betroffene Bürgerinnen und Bürger sowie spezifische Stakeholder, wie etwa Anwohner bei einem Industrieprojekt. In diesem Sinne richtet sich die Rechenschaftspflicht direkt an diejenigen, die unter einer Handlung leiden oder profitieren. Es besteht die normative Erwartung, dass der Verantwortungsträger die Interessen und Rechte dieser konkreten Adressaten angemessen berücksichtigt und zum Ausdruck bringt - etwa durch Partizipation an einem Entscheidungsprozess. Die zweite Dimension bezieht sich auf die Verantwortung gegenüber normativen Maßstäben. Dabei steht nicht eine konkrete Person im Zentrum, sondern die Einhaltung allgemein akzeptierter Regeln und Prinzipien, wie beispielsweise rechtlicher Vorgaben, ethischer Leitlinien oder wissenschaftlicher Standards. Der Verantwortungsträger muss demnach nicht nur seinen Mitmenschen Rede und Antwort stehen, sondern auch sicherstellen, dass sein Handeln mit übergeordneten Normen im Einklang steht. \cite{}
Quelle: Neuhäuser, Handbuch angwandte Ethik, seite: 215 - 221


\subsection{Ethik-Leitlinien}

Angesichts der potenziell disruptiven Wirkung und der schwer abzuschätzenden Tragweite des Quantencomputings ist es notwendig, ethisch fundierte Leitlinien zu definieren. Diese sollen verantwortliches Handeln in Forschung, Entwicklung und Anwendung der Technologie gewährleisten. Die im Folgenden vorgeschlagenen Leitlinien stützen sich dabei hauptsächlich auf zwei ethische Denkschulen, den Utilitarismus und die Verantwortungsethik, die in den Kapiteln 1.1 und 1.1.3 vorgestellt wurden. Der Utilitarismus bietet hierbei einen Rahmen für die Abwägung von potenziellem Nutzen und Schaden, während die Verantwortungsethik die Perspektive der Verantwortung der Stakeholder – also Entwickler, Unternehmen, Staaten usw. – einbezieht. Die Leitlinien sollen dabei als Orientierung für die verantwortungsvolle Entwicklung und Anwendung des Quantencomputings dienen. Die Prinzipien sind als Ausgangspunkt für Diskussionen zu verstehen. Sie sollen das Bewusstsein für ethische Herausforderungen schärfen und die Debatte innerhalb von Wissenschaft, Politik und Gesellschaft anregen, ohne einen abschließenden Charakter zu haben: 
\cite{} Quelle: Mauritz Kop und Ethik Leitlinien European Comission
\\
\\
\textbf{1. Maximiere den gesellschaftlichen Nutzen und minimiere den Schaden.}
Quantencomputing soll in erster Linie zur Förderung des kollektiven Wohlergehens eingesetzt werden. Dies Bedeutet, dass Anwendungen, die globale Herausforderungen adressieren, priorisiert werden sollen, während potentielle negative Risiken proaktiv minimiert werden müssen. 
\\
\\
\textbf{2. Verantwortung übernehmen und vorausschauend handeln}
Akteure im Bereich des Quantencomputings tragen eine besondere Verantwortung, sowohl die haftende als auch die sorgende Verantwortung, um die gegenwärtige und langfirstige Konsequenzen ihrer Handlungen zu berücksichtigen


\section{Stakeholder und Verantwortung}
Die rasante Entwicklung von Quatencomputing verspricht transformative Fortschritte in zahlreichen Bereichen, wie Chemie, Finanzwesen, oder Logistik.\textbf{ Quelle: https://www.mckinsey.de/news/presse/quantum-technology-monitor-2024}
Doch dieses Innovationspotenzial bringt auch komplexe ethische und gesellschaftliche Fragen mit sich. Wer trägt Verantwortung, wenn Quantencomputing unsere bestehenden Systeme grundlegend verändert?

\subsection{2.1 Identifikation relevanter Stakeholder im Quantencomputing-Ökosystem}
Die Identifizierung und Analyse der verschiedenen Gruppen und Entitäten, die den Fortschritt des Quantencomputings maßgeblich beeinflussen oder von seinen Auswirkungen betroffen sind, ist von zentraler Bedeutung. Dies ermöglicht ein umfassendes Verständnis der Machtdynamiken, Interessenkonflikte und potenziellen gesellschaftlichen Konsequenzen.

\subsubsection{2.1.1 Individuen: Nutzer, Betroffene und die Frage der Privatsphäre und Autonomie}

Individuen sind sowohl Nutzer als auch Betroffene von Quantentechnologien. Ihre Erfahrungen, Werte und Bedürfnisse sind fundamental für eine verantwortungsvolle Entwicklung. Hierbei ist entscheidend, ihre Autonomie und ihr Recht auf informierte Entscheidungen zu schützen, insbesondere da Quantencomputing menschliches Verhalten modellieren und potenziell beeinflussen könnte. Individuen sind direkt oder indirekt von den Auswirkungen betroffen und tragen die Werte, die in der Entwicklung berücksichtigt werden müssen. Um dies zu gewährleisten, ist es unerlässlich, einen gerechten Zugang zu den Vorteilen des Quantencomputing zu ermöglichen und Umschulungsprogramme zu unterstützen, um potenzielle Arbeitsplatzverlagerungen abzufedern. Die Förderung der öffentlichen Bildung und des Bewusstseins für die Potenziale und Grenzen des Quantencomputings ist wichtig, um übertriebene Erwartungen zu vermeiden und das Vertrauen der Öffentlichkeit durch transparente und faktengestützte Kommunikation aufzubauen. Zudem müssen ethische Grundsätze, Richtlinien und allgemein anerkannte menschliche und gesellschaftliche Werte eingehalten werden, um größeres Vertrauen zu gewinnen, anthropozentrisch und erklärbar zu sein sowie fair gegenüber dem Einzelnen zu bleiben und die Akzeptanz durch die Gesellschaft als Ganzes zu erhöhen.

\subsubsection{2.1.2 Unternehmen: Rolle in Entwicklung, Kommerzialisierung und ethischer Verantwortung}
Moralische Verantwortung wird Unternehmen zugeschrieben (Corporate Governance, Corporate Social Responsibility)
Treibt den technologischen Fortschritt voran, beteiligt sich an der Standardisierung, gewährleistet die Einhaltung von Vorschriften und liefert Fachwissen

\subsubsection{2.1.3 Forschung und Wissenschaft: Treiber der Innovation und ethische Reflexion}
Forschung und Wissenschaft: entscheidender Akteur im Dialog über die Governance von Quantencomputing. Ihre Rolle umfasst die Bereitstellung von Forschungsergebnissen und kritischen Analysen, um die komplexen Implikationen von Quantentechnologien zu verstehen. Sie ist unerlässlich für den Aufbau einer qualifizierten Arbeitskraft, die die ethischen, rechtlichen und gesellschaftlichen Aspekte von Quantentechnologien versteht. Ihre primäre Rolle ist die direkte Schaffung und Weiterentwicklung von Quantentechnologien, wobei sie sich für verantwortungsvolles Design, ethische Forschungspraktiken und die Vermeidung von Missbrauch einsetzen müssen.
Trägt mit Forschung, Erkenntnissen und kritischen Analysen bei und ist unerlässlich für den Aufbau einer qualifizierten Arbeitskraft

\subsubsection{2.1.4 Staaten und Internationale Organisationen: Geopolitik, Regulierung und globale Zusammenarbeit}
 Regierungen sind dafür verantwortlich, klare politische Ziele zu setzen, die Innovation mit dem öffentlichen Interesse in Einklang bringen. Sie schaffen legislative Grundlagen, gewährleisten Aufsicht und Durchsetzung und legen Rechenschaftspflicht und Haftung fest. Darüber hinaus fördern sie das öffentliche Vertrauen, investieren in Forschung und Entwicklung und leiten die internationale Zusammenarbeit. Im Kontext der Quanten-KI tragen sie auch die Verantwortung für nationale Sicherheitsimplikationen und die Planung der Migration zur Post-Quanten-Kryptographie (PQC). Regionale Beispiele umfassen die Europäische Union (EU AI Act , vorgeschlagener European Quantum Act ), die Vereinigten Staaten (National Quantum Initiative Act ) und China (Comprehensive Quantum Law ). 
Sind auch primäre wirtschaftliche Investoren und Treiber, oft über Verteidigungsinstitutionen
Momentane Entwicklungen von Hard- und Software im Quantencomputing in Deutschland werden vor allem durch staatliche Förderung getrieben. Die Bundesregierung plant bis 2026 drei Mrd. Euro für die Entwicklung von Quantentechnologien
Legt politische Ziele fest, schafft legislative Grundlagen, gewährleistet Aufsicht und Durchsetzung, fördert das Vertrauen der Öffentlichkeit und leitet die internationale Zusammenarbeit
Der globale Wettstreit findet zwischen Gesellschaftssystemen wie chinesischem Staatsmonopolismus, US-amerikanischen IT-Giganten und europäischer Marktwirtschaft statt
Herausforderungen bei der Erzielung globaler Abstimmung: Es gibt Herausforderungen, darunter geopolitischer Wettbewerb , ein "Regulierungsvakuum" oder eine "Governance-Lücke" , die Komplexität der Definition von "waffenfähiger" Quantentechnologie , Verifizierungsschwierigkeiten , mangelnder politischer Konsens und Bedenken hinsichtlich der Innovationshemmung

\subsubsection{2.1.5 Zivilgesellschaft und NGOs: Anwaltschaft, Sensibilisierung und Partizipation}
\begin{itemize}
    \item Internationale Organisationen: Organisationen wie das World Economic Forum (WEF) , die OECD  und die Vereinten Nationen (UN)  spielen eine entscheidende Rolle bei der Formulierung globaler Prinzipien, der Förderung der Zusammenarbeit und der Schaffung von Plattformen für den Dialog. Sie initiieren Vorschläge wie den "Quantum Acquis Planétaire"  und eine "Atomagentur für Quanten-KI" (IAEA-Q) , um globale Standards und Nichtverbreitungsmechanismen zu etablieren.
\end{itemize}
Zivilgesellschaft und NGOs: Organisationen der Zivilgesellschaft sind aktiv an der Bewältigung von Governance-Herausforderungen beteiligt. Sie setzen sich für ethische Überlegungen, Menschenrechte und verantwortungsvolle Entwicklung ein. Sie spielen eine entscheidende Rolle bei der Gestaltung des öffentlichen Diskurses und der Sicherstellung, dass Quanten-KI der Gesellschaft als Ganzes zugutekommt. Sie repräsentieren oft die Interessen der breiten Öffentlichkeit und der betroffenen Gemeinschaften.

    \begin{itemize}
        \item \textbf{Investoren:} deren Finanzentscheidungen beeinflussen die Richtung der Entwicklung
        \item \textbf{Journalisten und Medien:} prägen das öffentliche Bewusstsein und erleichtern den Dialog
        \item \textbf{Ethik und Gesellschaftsexperten: }helfen bei der Identifizierung und Analyse etischen Implikationen
\cite{Communities of Quantum Technologies: Stakeholder Identification, Legitimation, and Interaction}
(DOI:\href{http://dx.doi.org/10.13140/RG.2.2.25656.42240}{10.13140/RG.2.2.25656.42240})    \end{itemize}



\subsection{2.2 Verantwortungsdimensionen}
Die Verteilung von Verantwortung im Quantencomputing ist komplex und vielschichtig, da sie politische, wirtschaftliche und ethische Aspekte umfasst. Die Fragen, wer Entscheidungen trifft, wer für die Folgen haftet und wie mit Machtasymmetrien umgegangen wird, sind von zentraler Bedeutung für eine ethische Entwicklung und Nutzung von Quantencomputing.

\subsubsection{2.2.1 Entscheidungsfindung und Haftung: Wer trifft Entscheidungen und wer haftet?}
Die Frage, wer welche Entscheidungen für wen trifft und wer für die Folgen von Quantencomputing haftet, ist von grundlegender Bedeutung für die Governance. Die Entwicklung, Bereitstellung und Nutzung von Quantencomputing-Systemen erfordert Entscheidungen auf verschiedenen Ebenen: von Forschern, die Algorithmen entwerfen, über Unternehmen, die Hardware und Software entwickeln, bis hin zu Regierungen, die den Einsatz regulieren. Die Komplexität und der "Black-Box"-Charakter von Quantenalgorithmen erschweren die Zuweisung von Rechenschaftspflicht erheblich. Wenn ein Quantenalgorithmus einen Fehler macht, kann es schwierig sein, die Ursache oder den Mechanismus zu verstehen, der dazu geführt hat. Dies kann zu sogenannten "Verantwortungslücken" führen, bei denen unklar bleibt, wer zur Rechenschaft gezogen werden kann.

Die derzeitige Entwicklungsphase des Quantencomputings bedeutet, dass die Haftungsrahmenwerke weitgehend unterentwickelt sind. Die fehlende Klarheit darüber, wer die Verantwortung trägt, könnte die Entwicklung und den Einsatz von Quantencomputing-Systemen verlangsamen. Es ist daher unerlässlich, proaktive rechtliche Rahmenwerke zu schaffen, die die Verantwortung für Design, Bereitstellung und Ergebnisse definieren, insbesondere wenn Quantencomputing von der Forschung in kommerzielle Anwendungen übergeht. Die Betonung der menschlichen Aufsicht über KI-Systeme in Chinas Normen unterstreicht die Notwendigkeit, dass Menschen die letztendlich verantwortlichen Akteure bleiben. Dies erfordert auch eine klare Definition der Verantwortlichkeiten der beteiligten Parteien und die Etablierung von Rechenschaftsmechanismen, die eine Untersuchung der Verantwortung nicht vermeiden.

\subsubsection{2.2.2 Machtasymmetrien & Repräsentationsfragen: Ungleichgewichte im Einfluss adressieren}
Die Entwicklung des Quantencomputings ist durch erhebliche Machtasymmetrien gekennzeichnet. QC erfordert erhebliche Ressourcen, sowohl physischer als auch menschlicher Art, die nur wenigen Nationen zur Verfügung stehen.Dies könnte die globalen sozioökonomischen Unterschiede weiter vertiefen.

Die hohen Kosten und das spezialisierte Fachwissen, die für QC erforderlich sind, schaffen von Natur aus Machtungleichgewichte. Die aktuelle Investitionslandschaft, die durch die Dominanz privater US-amerikanischer Finanzierungen, Chinas staatlich gesteuerte Investitionen und Europas starke öffentliche, aber geringere private Investitionen gekennzeichnet ist, verschärft diese Asymmetrien. Zum Beispiel zieht die EU nur 5 \% der globalen privaten Finanzierung an, verglichen mit 50 \% in den USA. Dies macht es unerlässlich, bewusste Anstrengungen zur Demokratisierung des Zugangs zu unternehmen und eine inklusive Beteiligung von unterrepräsentierten Regionen und Gemeinschaften (z.B. dem Globalen Süden) sicherzustellen. Initiativen wie das "Internationale Jahr der Quantenwissenschaft und -technologie" der UNESCO im Jahr 2025 zielen darauf ab, diese Disparitäten zu verringern und die Forschungskapazitäten im Globalen Süden zu stärken.

\subsubsection{2.2.3 Wie ist Verantwortung verteilt – politisch, wirtschaftlich, ethisch? Wer kann, darf oder sollte ethische Rahmen setzen?}
Die Verteilung der Verantwortung für die ethische Gestaltung des Quantencomputing ist eine gemeinsame Aufgabe, die über verschiedene Sektoren hinweg getragen werden muss.

Auf \textbf{politischer Ebene} tragen Staaten und internationale Organisationen die Verantwortung für die Schaffung rechtlicher Rahmenbedingungen, die Festlegung von Standards und die Förderung internationaler Zusammenarbeit, um die Vorteile zu maximieren und Risiken zu mindern. Dies umfasst auch die Regulierung von Dual-Use-Anwendungen und die Gewährleistung der nationalen Sicherheit. Sie müssen sicherstellen, dass die Entwicklung von Quantencomputing mit nationalen Sicherheitsinteressen und globalen Stabilitätszielen vereinbar ist. Das EU-KI-Gesetz, obwohl nicht direkt auf QC zugeschnitten, bietet eine Analogie für Regulierung, die auf QC übertragen werden könnte, um in Bereichen wie kritische Infrastrukturen oder Strafverfolgung hohe Risiken zu mindern.


Auf wirtschaftlicher Ebene liegt die Verantwortung bei  Unternehmen und Investoren, die die Entwicklung und Kommerzialisierung von Quantencomputing vorantreiben. Sie sind verantwortlich für die ethische Entwicklung ihrer Produkte, die Gewährleistung eines fairen Zugangs zu ihren Technologien und die Minderung negativer wirtschaftlicher Auswirkungen wie Arbeitsplatzverdrängung. Ihre Verantwortung erstreckt sich auch auf die Investition in quantensichere Lösungen und die Anpassung ihrer Geschäftsmodelle.

Auf \textbf{ethischer Ebene} teilen sich alle Stakeholder die Verantwortung. Forscher tragen eine besondere Pflicht, die gesellschaftlichen Auswirkungen ihrer Arbeit zu bedenken und Ethik in den Designprozess zu integrieren. Ethik-Boards und Multi-Stakeholder-Panels sind entscheidend für die Definition und Implementierung ethischer Richtlinien. Internationale Gremien wie das WEF, die OECD und die UNESCO arbeiten aktiv an der Entwicklung ethischer Rahmenbedingungen und Richtlinien, um globale Standards zu etablieren. Die Betonung liegt auf einer antizipatorischen Ethik, die darauf abzielt, ethische Überlegungen von den frühen Phasen der Forschung und Entwicklung an einzubetten.

\subsubsection{2.2.4 Rahmenbedingungen: Akteure und Mechanismen zur Festlegung von Norme}
Die Festlegung von Rahmenbedingungen für das Quantencomputing ist eine gemeinsame Anstrengung verschiedener Akteure und Organisationen weltweit. Diese Bemühungen sind entscheidend, um die Entwicklung und den Einsatz von Quantencomputing in einer Weise zu steuern, die gesellschaftliche Werte widerspiegelt.

Globale Organisationen wie das World Economic Forum (WEF) und die National Academies of Sciences haben begonnen, Rahmenwerke für das Quantencomputing zu entwickeln. Das WEF hat beispielsweise "Quantum Computing Governance Principles" veröffentlicht, die Inklusivität, Gerechtigkeit, Sicherheit, Umweltschutz, Transparenz und Rechenschaftspflicht betonen. Diese Prinzipien sollen die Gestaltung und Einführung von Quantentechnologien leiten. Die OECD erforscht ebenfalls Prinzipien für die Entwicklung und Nutzung von Quantentechnologien und betont die Notwendigkeit eines multilateralen Konsenses. Die UNESCO hat 2025 zum "Internationalen Jahr der Quantenwissenschaft und -technologie" erklärt, um globale Zusammenarbeit zu fördern.

Auf nationaler Ebene entwickeln Regierungen und Standardisierungsorganisationen eigene Ansätze. Die USA haben mit dem NIST AI Risk Management Framework (AI RMF) einen Leitfaden zur Verbesserung der Robustheit und Zuverlässigkeit von KI-Systemen geschaffen, der auf Rechenschaftspflicht und Transparenz abzielt. China hat "Ethical Norms for New Generation Artificial Intelligence" veröffentlicht, die grundlegende Anforderungen wie die Förderung des menschlichen Wohlergehens, Gerechtigkeit und die Sicherstellung der Kontrollierbarkeit betonen, wobei der Mensch die letztendliche Verantwortung trägt.

Akademische Initiativen, wie das Quantum Ethics Project (QEP), tragen ebenfalls zur Gestaltung von Normen bei, indem sie Bildungsressourcen entwickeln und interdisziplinäre Diskussionen fördern. Sie betonen die Dringlichkeit, Gespräche über Quantenethik frühzeitig zu führen.

\subsection{2.3 Governance \& Steuerung ethischer Herausforderungen im Quantencomputing}
Die effektive Governance und Steuerung des Quantencomputings erfordert die Implementierung robuster Mechanismen, die Transparenz, Rechenschaftspflicht und Inklusivität gewährleisten.

\subsubsection{2.3.1 Ethik‑Boards und Multi‑Stakeholder‑Panels}
Ethik-Boards und Multi-Stakeholder-Panels sind zentrale Mechanismen zur Integration ethischer Überlegungen in die Entwicklung und Anwendung von Quantentechnologien.

    \item \textbf{Rolle und Bedeutung:} Diese Gremien dienen dazu, interne Ethik-Boards zu etablieren, ethische Überlegungen in die Forschungs- und Entwicklungsprozesse zu integrieren und externe Stakeholder einzubeziehen. Sie formulieren Prinzipien für ein verantwortungsvolles Design und eine verantwortungsvolle Einführung von Quantentechnologien.
    \item \textbf{Beispiele und Best Practices:} Das World Economic Forum (WEF) hat im Rahmen seines Quantum Computing Network Governance-Prinzipien entwickelt, die durch einen umfassenden Multi-Stakeholder-Co-Design-Prozess entstanden sind. Auch die National Academies of Sciences haben ethische Rahmenbedingungen für das Quantencomputing erarbeitet. Der US National Quantum Initiative Act sieht einen Beirat vor, der Vertreter aus Industrie, Universitäten und Bundeslaboren umfasst. Die EU plant einen hochrangigen Beirat zur strategischen Steuerung ihrer Quantenstrategie. Best Practices für die Multi-Stakeholder-Governance umfassen inklusive Repräsentation, Transparenz und Rechenschaftspflicht sowie kollaborative Problemlösung. Die Einbeziehung vielfältiger Stakeholder – Regierungen, Industrie, Wissenschaft und Zivilgesellschaft – ist entscheidend für die Legitimität und Wirksamkeit der Governance-Rahmenwerke.
    \item \textbf{Effektivität:} Solche Gremien ermöglichen ein frühzeitiges Eingreifen bei ethischen Fragen und sind entscheidend für die Schaffung legitimer, effektiver und auf gesellschaftliche Bedürfnisse reagierender Governance-Rahmenwerke.
    \textbf{Ethik-Boards \& Multi-Stakeholder-Panels:} Die Einrichtung von Ethik-Boards und Multi-Stakeholder-Panels ist entscheidend, um einen kontinuierlichen Dialog und eine Co-Kreation von Lösungen zu fördern. Der  

\textbf{Value Sensitive Design (VSD)-Ansatz} bietet einen robusten Rahmen, um sicherzustellen, dass Technologien von Natur aus mit den Werten und Interessen der Stakeholder übereinstimmen und diese verkörpern, indem sie diese direkt in den Designprozess einbeziehen.


\subsubsection{2.3.2 Internationale Regulierungsansätze (z. B. KI‑Analogien)}
Die Notwendigkeit global koordinierter Regeln für Quantentechnologien wird angesichts ihrer grenzüberschreitenden Auswirkungen immer deutlicher.

\begin{itemize}
    \item \textbf{Bedarf an globaler Koordination:} Angesichts der globalen Reichweite und der potenziellen Auswirkungen von Quantentechnologien sind adaptive, global koordinierte Regeln unerlässlich. Internationale Zusammenarbeit ist entscheidend, um eine "Quanten-Kluft" zu verhindern und die Vorteile gerecht zu verteilen.
    \item \textbf{Analogien zur KI-Regulierung:} Einige Stakeholder greifen auf die Ethik und die regulatorischen Rahmenbedingungen der KI zurück, um Orientierung für das Quantencomputing zu finden.Beispiele hierfür sind das NIST AI Risk Management Framework in den USA und Chinas KI-Ethikrichtlinien, die Leitlinien für den verantwortungsvollen Umgang mit KI bieten. Die EU hat mit dem KI-Gesetz einen umfassenden Regulierungsansatz für KI-Systeme basierend auf Risikostufen etabliert.
    \item \textbf{Grenzen der KI-Analogien:} Es wird jedoch ausdrücklich davor gewarnt, ethische Prinzipien und Richtlinien unkritisch von der KI zu übernehmen, da Quantencomputing sich in materiellen Aspekten, dem Entwicklungsstadium und den Entwicklungsmethoden erheblich unterscheidet. Dies unterstreicht die Notwendigkeit eines spezifischen Teilgebiets der Quantencomputing-Ethik.
    \item \textbf{Bestehende internationale Bemühungen:} Der US National Quantum Initiative Act fördert die öffentlich-private Zusammenarbeit.Die EU-Quantenstrategie zielt darauf ab, Europa bis 2030 zu einem weltweit führenden Akteur im Quantenbereich zu machen. China investiert massiv in Quantentechnologien mit einem "Whole-of-Society"-Ansatz.Internationale Organisationen wie das WEF, die OECD und die UNESCO entwickeln Prinzipien und fördern die Zusammenarbeit.
\end{itemize}
\begin{itemize}
    \item \textbf{Herausforderungen:} Der globale Wettbewerb führt zu einer Fragmentierung der Forschung, und Spannungen in der internationalen Zusammenarbeit entstehen aufgrund von Sicherheitsbedenken, Dual-Use-Anwendungen und dem Wettlauf um technologische Führung.
\end{itemize}

\subsubsection{2.3.3 Offene Standards vs. Proprietäre Entwicklung: Implikationen für Zugang, Innovation und Gerechtigkeit}
Die Wahl zwischen offenen Standards und proprietärer Entwicklung hat tiefgreifende Implikationen für den Zugang zu Quantentechnologien, die Geschwindigkeit der Innovation und die Verteilung ihrer Vorteile.

Proprietäre Entwicklung, die oft von großen Technologieunternehmen vorangetrieben wird, ermöglicht es diesen Unternehmen, Wettbewerbsvorteile durch den Schutz ihres geistigen Eigentums und die Kontrolle über ihre Technologie-Stacks zu erzielen. Dies kann zu schnelleren Innovationen innerhalb dieser geschlossenen Ökosysteme führen, da Ressourcen gebündelt und Entscheidungen zentralisiert werden können. Allerdings kann dieser Ansatz den Zugang zu QC-Ressourcen und -Wissen begrenzen, was Ungleichheiten schaffen könnte. Wenn der Zugang zu Quantencomputing-Ressourcen auf diejenigen mit dem notwendigen Fachwissen und der Finanzierung beschränkt ist, kann dies Auswirkungen auf Einzelpersonen und die Gesellschaft insgesamt haben. Zudem kann die Verwendung von nicht verifizierten oder proprietären Algorithmen in der Quantencomputing-Forschung zu Bedenken hinsichtlich Transparenz und Rechenschaftspflicht führen.

Im Gegensatz dazu fördern offene Standards und Open-Source-Entwicklung Transparenz, unabhängige Überprüfung und die breitere Beteiligung an der Entwicklung von Quantentechnologien. Open-Source-Quantenforschungsinitiativen, Technologietransfer- und Austauschabkommen sowie Investitionen in die Quantenbildung in Entwicklungsländern können dazu beitragen, einen gerechteren Zugang zu gewährleisten. Eine offene Entwicklung kann auch die Zusammenarbeit über Grenzen hinweg fördern und sicherstellen, dass Quantentechnologien letztendlich der breiteren wissenschaftlichen Gemeinschaft und der Gesellschaft zugutekommen.


\section{3. Normative Spannungsfelder  }
Die Verteilung von Verantwortung im Quantencomputing ist komplex und vielschichtig, da sie politische, wirtschaftliche und ethische Aspekte umfasst. Die Fragen, wer Entscheidungen trifft, wer für die Folgen haftet und wie mit Machtasymmetrien umgegangen wird, sind von zentraler Bedeutung für eine ethische Entwicklung und Nutzung von Quantencomputing.



3.1 \textbf{Zugang \& Gerechtigkeit} 
Die Vision eines breit zugänglichen Quantencomputings weckt die Erwartung, technologische Teilhabe grundlegend neu zu gestalten. Offene Cloud-Plattformen, frei verfügbare Software-Frameworks sowie internationale Bildungskooperationen könnten Studierenden, Start-ups und Forschungseinrichtungen ohne eigene Kryo-Labore den direkten Zugriff auf reale Quantenprozessoren erlauben. In einer idealen Ausprägung senken solche Open-Access-Wege nicht nur Eintrittsbarrieren, sondern schaffen neue Lernökosysteme, in denen Programmier-AGs an Schulen mit Nobelpreislaboren vernetzt sind; ganze Regionen könnten so erstmals eigenständig Innovationspfade beschreiten.

Doch genau hier öffnet sich ein tiefes normatives Spannungsfeld. Virtueller Zugang allein garantiert keine strukturelle Gerechtigkeit, solange die physischen Schlüsselressourcen – supraleitende Chip-Fertigung, isotopenreine Silizium-28-Wafer oder energiefressende Dilution-Kühlsysteme – in den Händen weniger ökonomisch mächtiger Akteure verbleiben. Entsteht eine Quanten-Elite, kann sie Forschungsagenden, Standardisierungsprozesse und Lizenzmodelle diktieren. Für Staaten mit begrenzter Wirtschaftskraft droht eine neue technologische Abhängigkeit: Rechenzeit wird zwar „on demand“ angeboten, echte Souveränität über kritische Infrastruktur jedoch verwehrt.

Hinzu kommt das Phänomen eines potenziellen „Braindrain“. Hochqualifizierte Talente aus dem Globalen Süden erhalten Stipendien an hardwareführenden Universitäten, bleiben dort jedoch häufig dauerhaft, weil heimische Institutionen weder Infrastruktur noch Karrierepfade bieten. So vergrößert sich die Wissenskluft, während die Herkunftsländer weiterhin auf externen Quanten-Dienstleistungen angewiesen sind. Selbst umfangreiche Open-Source-Lehrpläne können diese Lücke nicht schließen, wenn vor Ort Laborkapazitäten und Wartungskompetenz fehlen.

Auch die ökonomische Gestaltung von Freemium-Tarifen für Cloud-Rechenzeit wirft Gerechtigkeitsfragen auf: Wer sich längere und komplexere Programme leisten will, muss zahlen – oft in Währungen und mit Zahlungsmitteln, die in Schwellen- und Entwicklungsländern schwer zugänglich sind. Dadurch entsteht eine digitale Schichtstruktur: kostenfreie Einstiegskurse für alle, fortgeschrittene Quantenressourcen für zahlungskräftige Kundschaft.

Ein weiterer Aspekt betrifft das geistige Eigentum. Selbst wenn Quantenalgorithmen quelloffen publiziert werden, sind sie häufig auf proprietäre Hardware zugeschnitten. Ohne plattformunabhängige Schnittstellen drohen Code-Lock-ins, die kollaborative Innovation einschränken. Regulatorische Ansätze können hier ansetzen, indem sie offene Hardware-Abstraktionsebenen und portierbare Compiler vorschreiben, sodass Wissenstransfer nicht an Unternehmensgrenzen scheitert.

Die normative Kernfrage verschiebt sich somit: Nicht ob Quantencomputing offen oder exklusiv sein wird, sondern welche Tiefenebenen des Zugangs – von Bildungsinhalten über Testzugänge bis hin zu Fertigungskompetenz – erforderlich sind, um echte Chancengleichheit zu erreichen. Gelingt es, Hardware-Kapazitäten, Ausbildungsförderung und wirtschaftliche Teilhaberechte global neu zu verteilen, kann Quantencomputing Innovationslücken schließen und wissenschaftliche Diversität stärken. Misslingt dieser Balanceakt, droht die Technologie zum Verstärker bestehender Ungleichheiten zu werden – und damit genau jene digitale Hierarchie zu reproduzieren, die sie eigentlich überwinden sollte. (Coenen et al., 2022)

3.2 \textbf{Sicherheit und Kontrolle}

Quantum Key Distribution (QKD) gilt als vielversprechendste Anwendung für eine radikal neue Sicherheits­­architektur: Da bereits der Versuch des Abhörens unweigerlich den Quantenzustand verändert, lässt sich Manipulation physikalisch nachweisen. In der Praxis eröffnet das die Chance, die verwundbarste Stelle klassischer Kryptosysteme – den Schlüsselaustausch – in ein nachweisbar abhörsicheres Verfahren zu überführen. Wird QKD konsequent in Glasfaserringen großer Metropolen oder über satellitengestützte Links implementiert, könnten Regierungen, Betreiber kritischer Infrastrukturen und sensible Wirtschafts­­zweige einen Kommunikations­­kanal aufbauen, der selbst künftigen Quanten­­angreifern standhält. Das Vertrauen in digitale Prozesse würde dadurch erheblich gestärkt: Telemedizinische Fern­operationen könnten Patientendaten ohne Restrisiko übertragen, Abstimmungssysteme würden ein Integritäts­niveau erreichen, das Wahlmanipulation faktisch ausschließt, und industrielle Steuerungsnetze ließen sich so absichern, dass Ausfall­angriffe auf Energienetze oder Wasserwerke scheitern. Darüber hinaus birgt QKD das Potenzial, vollständig neue Geschäfts­modelle zu generieren – etwa „trusted node as a service“, bei dem zertifizierte Knoten Dienstleistungen für Banken, Cloud-Provider oder Forschungskonsortien anbieten.

Demgegenüber stehen jedoch Risiken, die aus der Kluft zwischen theoretischer Perfektion und industrieller Wirklichkeit resultieren. Reale QKD-Geräte weisen zwangsläufig Imperfektionen auf: Mininale Abweichungen in Laserquellen oder Detektoren eröffnen Seitenkanäle, über die Angreifer verdeckt Informationen auslesen. Fehlkalibrierte Avalanche-Photodioden lassen sich mit hellen Lichtblitzen in einen deterministischen Modus zwingen („blinding attack“) und umgehen so die quanten­­physikalische Alarm­schranke; unzureichend abgeschirmte Modulatoren bieten Einfallstore für Trojan-Horse-Attacken, bei denen eingekoppeltes Licht verräterische Signaturen in den Rückstreuungen erzeugt; und bei endlichen Schlüssellängen führen statistische Fluktuationen dazu, dass die theoretisch garantierte Fehlerschranke unterschritten wird und dennoch Informationslecks entstehen. Solche Schwachstellen machen deutlich, dass QKD keineswegs per se unknackbar ist, sondern von sorgfältig geprüfter Hardware, vertrauens­­wür­digen Lieferketten und laufender Sicherheits­­zertifizierung abhängt.

Hinzu kommt die makro­ökono­mische Dimension: Der Aufbau großskaliger QKD-Netze erfordert milliardenschwere Investitionen in Spezial­faser, Satelliten-Repeater, Kryo-Optik und Quanten-Zufalls­generatoren. Viele dieser Komponenten sind exportkontrolliert oder werden von wenigen Herstellern in geo­poli­tisch sensiblen Regionen gefertigt. Wer die physische Hardware kontrolliert, gewinnt nicht nur technischen, sondern strategischen Einfluss – bis hin zur Gefahr, dass einzelne Staaten oder Konzerne die globale Sicherheits­­infra­struktur dominieren, Standards festlegen und politische Zugangs­bedingungen diktieren. Im Extremfall entstünde ein neues Wettrüsten, bei dem Staaten versuchen, fremde QKD-Knoten zu infiltrieren oder Lieferketten gezielt zu stören, um ihre eigene Kommunikations­­überlegenheit zu sichern.

Das Spannungsfeld verschärft sich weiter durch die notwendige Kopplung von QKD an klassische Netze: Schlüsselmanagement, Authentisierung und Firmware-Updates bleiben nicht-quantische Angriffsflächen. Ohne robuste Schnittstellenstandards kann die Integration selbst hochsicherer Quantenlinks ausgehebelt werden, wenn klassische Endpunkte kompromittiert sind. Daraus folgt, dass eine zukunftsfähige Sicherheits­strategie technische Präzision (hochqualitative Komponenten, unabhängige Zertifizierung, Open-Hardware-Audits) mit politischer und wirtschaftlicher Governance (transparente Exportregeln, internationale Auditverfahren, faire Marktzugänge) verknüpfen muss. Erst wenn Kalibrierungs­­protokolle offen gelegt, Lieferketten diversifiziert und Zertifizierungs­­stellen grenz­über­schreitend akkreditiert werden, kann QKD sein volles Schutzniveau entfalten, ohne neue Macht­­asymmetrien oder schwer kontrollierbare Angriffspunkte zu schaffen. (Sun & Huang, 2022)


3.3 \textbf{Nachhaltigkeit und Umwelt}
Quantencomputing wird häufig als „Turbo“ für ökologische Problemlösungen beschrieben. Auf der Chancen­­seite steht das Potenzial, Klima- und Energie­modelle um Größen­ordnungen schneller sowie präziser zu berechnen. Variationale Quanten­algorithmen ermöglichen eine bislang unerreichte Auflösung von Aerosol­prozessen, Wolken­bildung, Ozean­zirkulation und Kohlenstoff­kreisläufen – Parameter, die in heutigen Supercomputer­szenarien oft grob skaliert werden müssen. Dadurch lassen sich Emissions­pfade robuster validieren, Extrem­wetter­ereignisse früher prognostizieren und Gegen­maßnahmen gezielter planen. Quanten­optimierer können darüber hinaus Stromnetze feiner takten, den Einsatz erneuerbarer Energiequellen in Echtzeit balancieren und Transport­ketten so reorganisieren, dass Leer­fahrten minimiert und Routen treib­stoff­effizient angepasst werden. Ebenso verheißungsvoll ist die Suche nach neuen Katalysatoren: Quantenchemische Simulationen können in Stunden statt Jahren Moleküle identifizieren, die Ammoniak­synthese, Zement­produktion oder Batterienressourcen energie­ärmer gestalten – jede eingesparte Kilowattstunde mindert den CO₂-Ausstoß unmittelbar.

Demgegenüber stehen Risiken, die primär von der Hardware­seite ausgehen. Die meisten aktuellen Qubit-Plattformen erfordern Tempera­turen nahe dem absoluten Nullpunkt; Dilution-Kryostaten benötigen Dauerleistungen von mehreren Dutzend Kilowatt. Zwar könnten Rechen­zentren theoretisch vollständig mit erneuerbarem Strom betrieben werden, doch die Herstellung isotopen­reiner Silizium-28-Wafer, hochreiner Halbleiter und Edelmetall­verdrahtungen erhöht heute schon den ökologischen Fußabdruck. Steigt die Nachfrage, verschärft sich der Konkurrenz­druck um seltene Isotope, Helium-3 oder Niobium – Rohstoffe, deren Gewinnung energie- und wasser­intensiv ist. Selbst Recycling­strategien stoßen hier an Grenzen: Viele Quanten­chips sind hochspezialisierte Einweg­produkte, deren Aufarbeitung technisch anspruchsvoll und wirtschaftlich unattraktiv bleibt.

Ein geografischer Aspekt verschärft die Lage weiter: Die Vorfertigung hochreiner Komponenten verlagert sich oft in Regionen mit günstiger Energie­politik, aber laxeren Umwelt­standards. So könnten CO₂-intensive Herstellungsschritte exportiert werden, während saubere Rechenzentren in Industrieländern von dieser Wertschöpfungsschicht profitieren – eine Verlagerung der Emissionen statt ihrer Reduktion. Auch die infrastruktur­seitige Integration stellt Herausforderungen: Kühlwasser, Abwärme­management und Stromspitzen müssen städtisch eingeplant werden, sonst verdrängen Quanten­rechen­zentren kommunale Nachhaltigkeits­ziele.

Ein tragfähiger Nachhaltigkeits­pfad verlangt daher ein doppeltes Vorgehen. Erstens braucht es strikte Life-Cycle-Analysen, die nicht nur den Betrieb, sondern Rohstoff­gewinnung, Transport und End-of-Life-Entsorgung erfassen. Nur wenn die eingesparte Energie beziehungsweise das vermiedene CO₂ die Produktion und Instand­haltung deutlich übertreffen, ist der Einsatz ökologisch zu rechtfertigen. Zweitens müssen Industrie­standards auf Modularität, Material­substitution und Kreislauf­wirtschaft setzen: Alternativen zu Helium-3, modulare Qubit-Blöcke, die sich nachrüsten statt neu herstellen lassen, oder Abwärme­rückgewinnungssysteme, die den Kältebedarf teilweise energetisch kompensieren. Ergänzend sollten politische Instrumente wie Carbon-Pricing, Umwelt­zertifikate und Export­kontrollen sicherstellen, dass ökologische Kosten sichtbar bleiben und nicht externalisiert werden.

Erst wenn solche Leitplanken früh etabliert sind, hat Quantencomputing die Chance, sich von einem ressourcen­intensiven Nischen­experiment zu einer Schlüssel­technik der klimaneutralen Transformation zu entwickeln. Gelingt das nicht, droht eine neue Generation energiehungriger Rechen­zentren, die das Klima­problem nur verschiebt, statt es zu lösen.(Root, 2025; Schwabe et al., 2025)


3.4 \textbf{Autonomie und Verantwortlichkeit}
3.4.1 \textbf{”Black-Box“-Entscheidungen durch Quantenalgorithmen}
Die fortschreitende Entwicklung von Quantenalgorithmen eröffnet vielfältige neue Anwendungsmöglichkeiten, bringt aber auch erhebliche ethische Herausforderungen mit sich – insbesondere im Hinblick auf Entscheidungsprozesse, die sich unserer Kontrolle oder unserem Verständnis entziehen. Quantenalgorithmen basieren oft auf probabilistischen Prinzipien, die es erschweren, einzelne Ergebnisse eindeutig zu erklären oder zurückzuverfolgen. Wenn Systeme autonome Entscheidungen treffen, deren Logik für Nutzer oder Entwickler nicht transparent ist, spricht man von sogenannten „Black-Box“-Entscheidungen.

In sensiblen Bereichen wie Justiz, Medizin oder Sicherheit können solche intransparenten Entscheidungen gravierende Folgen für Individuen und Gesellschaft haben. Die Schwierigkeit besteht darin, Verantwortung klar zuzuweisen, wenn weder Entwickler noch Anwender genau nachvollziehen können, wie ein Ergebnis zustande kam (Stahl, 2021). Hier stellt sich die Frage, wie viel Autonomie ein technisches System überhaupt haben darf – und wer letztlich die Kontrolle behält.

 3.4.2 \textbf{Verantwortungslücken bei Systemversagen}
 Mit wachsender Komplexität von Quantencomputersystemen steigt auch das Risiko von Verantwortungslücken. Anders als bei klassischen IT-Systemen, bei denen Fehlerquellen oft identifizierbar und zuordenbar sind, kann bei quantenbasierten Systemen ein Versagen durch viele Ebenen der Technologie bedingt sein – von physikalischen Fehlern im Qubit-Handling bis zu unvorhersehbaren Algorithmusverläufen.

Diese komplexe Verantwortungsdiffusion erschwert die juristische und ethische Zurechenbarkeit. Wer haftet, wenn ein quantenbasiertes Entscheidungssystem fehlerhaft urteilt – der Entwickler, der Betreiber, der Datenlieferant? Die bestehenden rechtlichen Rahmenwerke reichen oft nicht aus, um solche Situationen angemessen zu regeln. Daher bedarf es eines ethisch fundierten Verständnisses von „geteilter Verantwortung“, das neue Kooperations- und Kontrollmodelle zwischen verschiedenen Akteuren vorsieht (Dignum, 2019).

3.4.3 \textbf{Intransparente Systeme }
Ein zentrales Problem im Kontext von Verantwortung ist die mangelnde Transparenz quantenbasierter Systeme. Während in klassischen Systemen bereits große Anstrengungen zur Erklärbarkeit („Explainability“) unternommen werden, ist dies bei Quantenalgorithmen besonders herausfordernd. Ihre auf Überlagerung und Verschränkung basierenden Prozesse lassen sich nur schwer in klassische Denkstrukturen übersetzen.

Diese Intransparenz gefährdet nicht nur das Vertrauen der Nutzer, sondern auch die Möglichkeit, Fehlverhalten oder Diskriminierung aufzudecken. Besonders kritisch ist dies bei öffentlich relevanten Entscheidungen, etwa in sozialen Diensten oder im Finanzwesen. Deshalb wird die Entwicklung von „Quantum Explainability“-Ansätzen entscheidend sein, um Akzeptanz und Kontrolle zu ermöglichen – auch wenn diese Bemühungen derzeit noch am Anfang stehen.

 
\paragraph{Fazit:Die ethischen Herausforderungen im Bereich \textbf{Autonomie und Verantwortlichkeit} zeigen, dass die Entwicklung von Quantencomputing nicht nur eine technische, sondern vor allem eine gesellschaftliche Aufgabe ist. Entscheidungen müssen nachvollziehbar, Verantwortlichkeiten klar verteilt und Systeme transparent gestaltet sein – sonst drohen technologische Macht ohne demokratische Kontrolle.
 In Zukunft wird sich Quantencomputing nur dann breit durchsetzen können, wenn es gelingt, Vertrauen aufzubauen – durch internationale ethische Standards, neue Formen der Governance und eine frühzeitige Einbettung von Verantwortung in die Technologieentwicklung selbst. Bildung, Regulierung und Kooperation werden hierbei Schlüsselrollen spielen.}

 

 
 

 

\section{4. Gestaltungsoptionen und Empfehlungen (Optional)}

\section{5. Fazit und Ausblick}





















\section{Chancen und Risiken}

\subsection{Chancen}

\item Grundlagen
\begin{itemize}
    \item Die ethischen Chancen des Quantencomputings umfassen nicht nur technische Leistungssteigerungen, sondern insbesondere die positiven sozialen, wirtschaftlichen und politischen Auswirkungen dieser Technologien, sofern sie unter Fairness- und Verantwortungsaspekten eingesetzt werden. \cite{arrow_holistic_2023}

In diesem Kontext ist nicht nur der unmittelbare Einsatz der Technologie von Relevanz, sondern auch die Entwicklung, die anhand der vier Dimensionen Antizipation, Reflexivität, Inklusion und Reaktionsfähigkeit – mit denen technologische Entwicklungen systematisch auf ihre ethischen Chancen hin bewertet und bereits im Design integriert werden – erfolgt. Quelle: https://doi.org/10.1016/j.respol.2013.05.008

\item \item Gesundheit \& Medizin
Im Bereich der Gesundheit und Medizin bietet Quantencomputing ein Potenzial hinsichtlich molekularer Simulationen, Präzisionsmedizin, Diagnostik, Radiotherapie, Arzneimittelforschung und Preisstrategien. Quelle: \href{https://doi.org/10.3390/fi15030094}{\textbf{https://doi.org/10.3390/fi15030094}}

\item Umwelt \& Klimaschutz
Quantencomputing hat das Potential, die Berechnung von Differentialgleichungen in Erdsystemmodellen signifikant zu beschleunigen und maschinelles Lernen auf Quantenhardware zu ermöglichen. Dadurch können bislang unzureichend abgebildete lokale Prozesse, wie beispielsweise Wolkenbildung und Turbulenzen, feiner und genauer dargestellt werden. Quelle: https://doi.org/10.48550/arXiv.2502.10488

\item Soziale Gerechtigkeit \& Teilhabe
\begin{itemize}
    \item Open-Source-Software im Bereich des Quantencomputings ermöglicht die Entwicklung und den Test von Algorithmen, ohne dass eine proprietäre Quantenmaschine erforderlich ist. Dies ist ein wesentlicher Aspekt, um einen gleichberechtigten Zugang zu Forschung und Innovation zu gewährleisten. Quelle: Fingerhuth et al
    \item Moderne Quanten-Cloud-Plattformen wie IBM Quantum Experience oder Amazon Braket offerieren nicht nur die Bereitstellung von Rechenzeit, sondern auch interaktive Lernumgebungen und Tutorials. Es wird den Einsteiger:innen somit die Möglichkeit geboten, weltweit praxisnah zu programmieren und zu experimentieren. Quelle: Nguyen et al.

\end{itemize}
\item Dititale Souveränität & Sicherheit
Quantencomputing eröffnet neue Möglichkeiten, um kritische Infrastrukturen vor Cyberangriffen zu schützen und somit die digitale Souveränität von Individuen und Gemeinschaften zu stärken. Durch den Einsatz von quantensicheren Kryptografietechnologien und innovativen Abwehrmechanismen können die Datenintegrität und die Privatsphäre auf ein bislang unerreichbares Niveau gehoben werden.  Quellen: Faruk et al, & https://doi.org/10.48009/1_iis_2024_125
\item 


\end{itemize}
\item Infrastruktur \& Mobilität
Quantenalgorithmen haben das Potential, die Effizienz von Verkehrsflüssen, Logistiknetzwerken und Routenplanungen zu steigern. Dies wird durch die Lösung von Optimierungsproblemen in Parallelität erreicht, was wiederum zur Reduzierung von Staus beiträgt und die Auslastung von Verkehrswegen sowie autonom fahrenden Fahrzeugen erhöht. Quelle: zhuang et al

Im Rahmen des Q-GRID-Projekts wird der Frage nachgegangen, inwiefern Quantenoptimierung die Effizienz und Ausfallsicherheit dezentraler Energieerzeugung und -übertragung sowie neuartiger Energiemarkt-Modelle (beispielsweise Peer-to-Peer-Handel, Mikrogrids) optimieren kann. Quelle: Blenninger et al. 


\item Fazit


\subsection{Risiken}
Datenschutz \& Informationssicherheit
\begin{itemize}
    \item Der Missbrauch von Technologien, einschließlich unbefugtem Zugriff auf sensible Daten durch Quantenhacking oder die Schaffung von Systemen, denen es an Transparenz und Rechenschaftspflicht mangelt, wird ebenfalls als potenzielle ethische und gesellschaftliche Probleme genannt, insbesondere im Zusammenhang mit fehlenden regulatorischen Rahmenbedingungen \cite{umbrello_quantum_2024}
\end{itemize}
\begin{itemize}
    \item Machtasymmetrien und Monopolisierung
    \item Gesellschaftliche Ungleichheit
    \item Unvorhersehbarkeit \& Kontrollverlust
    \item Dual-Use-Problematik
    \item Inkompatibilität
\end{itemize}
Allgemeine ethische Herausforderungen und Risiken umfassen Bedenken hinsichtlich:

\subsubsection{\textbf{1. Technische Risiken}}
\begin{itemize}
    \item Systemzuverlässigkeit und Stabilitätsprobleme
    \item Gefahr von Quantum Hacking
    \item \textbf{Technologischer Wandel} bzw. schnelle \textbf{Obsoleszenz} (Überalterung neuer Technologien)
    \item Beeinträchtigung der \textbf{Funktionalität} und \textbf{Sicherheit} von Quanten-Technologien
\end{itemize}

\subsubsection{\textbf{2. Ethische und gesellschaftliche Risiken}}
\begin{itemize}
    \item \textbf{Verletzung der Privatsphäre} durch neue Möglichkeiten der Datenanalyse
    \item \textbf{Bias (Voreingenommenheit)} in Entscheidungsalgorithmen
    \item \textbf{Mangel an Transparenz} und \textbf{fehlende Rechenschaftspflicht}
    \item Konflikt mit gesellschaftlichen Normen und \textbf{ethischen Prinzipien}
\end{itemize}

\subsubsection{\textbf{3. Ökonomische Risiken}}
\begin{itemize}
    \item \textbf{Ungleicher Zugang} zu Quanten-Technologien (Digital Divide)
    \item Verstärkung bestehender \textbf{gesellschaftlicher oder wirtschaftlicher Ungleichheiten}
    \item \textbf{Monopolisierung} oder Machtkonzentration bei wenigen Akteuren
    \item Risiken für eine faire \textbf{Verteilung wirtschaftlicher Vorteile}
\end{itemize}

\subsubsection{\textbf{4. Umweltbezogene Risiken}}
\begin{itemize}
    \item \textbf{Hoher Energieverbrauch} von Quantencomputern
    \item \textbf{Ökologische Auswirkungen} durch Herstellung und Betrieb
    \item Risiken für die \textbf{Nachhaltigkeit} und \textbf{Umweltverantwortung} beim Einsatz dieser Technologien
\end{itemize}

\cite{umbrello_quantum_2024}


\section{Freier Wille für Maschinen?}



\section{Diskussion}

\textbf{Wie können Chancen maximiert, Risiken minimiert werden?}
Klarheit und Transparenz hinsichtlich der Richtlinien und Protokolle zur Datenverwaltung sowie systematische Prüfungen der Quanten-Dienstleister sind entscheidend, um größtmögliche Flexibilität bei der Bewertung quantentechnologischer Chancen zu ermöglichen, Risiken zu minimieren und verantwortungsvolle Forschung und Innovation zu fördern .
quelle{https://www.ey.com/en_uk/insights/emerging-technologies/why-innovation-leaders-must-consider-quantum-ethics}


\textbf{Was bedeutet „verantwortungsvolle Quantenforschung“?
Ethik als Designprinzip}

\printbibliography
