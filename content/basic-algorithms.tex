%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Grundlegende Quantenalgorithmen}
\label{basic_algorithms} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

\chapterauthor{Vladimir Alyoshin, Gian-Luca Eberling}

\abstract*{some abstract}

\abstract{some abstract}

\section{Shor-Algorithmus: Faktorisierung und diskreter Logarithmus}
\subsection{Idee: Primfaktorzerlegung}
\subsection{Diskreter Logarithmus}
\subsection{Quantum Fourier Transformation}
\subsection{Anwendung: RSA-Algorithmus brechen}

\section{Grover-Algorithmus: Quantum-Suche}
In der Informatik zählt die Datenverarbeitung zu den gefragtesten Aufgaben. In der heutigen Zeit ist die Möglichkeit, große Datenmengen zu durchsuchen — insbesondere unstrukturierte Daten — ein wesentlicher Aspekt der Datenanalyse. Um dies zu veranschaulichen, betrachten wir folgendes Beispiel:\\ 

\noindent Angenommen, wir möchten einen bestimmten Kunden in der Datenbank eines Online-Shops finden (unter der Annahme, dass die Datenbank nicht indexiert ist). Bei Verwendung eines klassischen Computers benötigen wir im schlechtesten Fall $N$ Iterationen, wobei $N$ die Anzahl der Zeilen in der Tabelle darstellt. Im durchschnittlichen Fall sind etwa $N/2$ Operationen erforderlich. Das bedeutet, dass alle Elemente der Tabelle durchlaufen werden müssen, sofern uns die genaue Position des gesuchten Kunden nicht bekannt ist — bis dieser schließlich gefunden wird.\\

\noindent Wenn jedoch unsere Datenbank auf Quantenberechnungen basiert, können wir Quanten-Suchalgorithmen wie den Grover-Algorithmus einsetzen. In diesem Fall lässt sich das gesuchte Element mit etwa $\sqrt{N}$ Operationen finden. Zwar führt dieser Algorithmus nicht zu einer exponentiellen Beschleunigung der Suche und muss häufig mehrfach iterativ aufgerufen werden, dennoch stellt die quadratische Laufzeit bereits eine bedeutende Optimierung dar.

\subsection{Grundlagen: Unstrukturiertes Suchproblem}
Bevor wir uns dem Grover-Algorithmus zuwenden, betrachten wir folgendes Beispiel: Stellen wir uns vor, auf dem Tisch liegen vier Spielkarten verdeckt. Eine dieser vier Karten ist die Pik-Dame, und unsere Aufgabe besteht darin, sie zu finden. Wie viele Karten müssen wir im Durchschnitt aufdecken, um die Pik-Dame zu identifizieren? Im besten Fall finden wir die gesuchte Karte bereits beim ersten Versuch. Im schlechtesten Fall müssen wir drei Karten umdrehen — wenn keine von ihnen die Pik-Dame ist, dann bleibt nur noch die vierte, nicht aufgedeckte Karte als einzig mögliche Lösung. Im Durchschnitt müssen wir 2{,}25 Karten aufdecken, um die Pik-Dame zu finden.\\

\noindent Formulieren wir nun das Beispiel um: Anstelle von Spielkarten betrachten wir eine binäre Reihenfolge natürlicher Zahlen — nämlich $00$, $01$, $10$ und $11$. Nehmen wir an, die Pik-Dame entspricht dabei der Zahl $10$. Wir definieren eine Funktion $f$, die den Wert $1$ zurückgibt, wenn das Eingabemuster $10$ ist, und $0$ in allen anderen Fällen. Somit lässt sich das Problem wie folgt formal ausdrücken:

\begin{definition}[Unstrukturiertes Suchproblem]
Sei $f\colon \{0, 1\}^n \rightarrow \{0, 1\}$ eine abstrakte Funktion mit $f(x) \in \{0, 1\}$. Gesucht ist ein Wert $x$, sodass $f(x) = 1$, falls ein solcher Wert existiert; andernfalls soll das Ergebnis $0$ sein.
\end{definition}

\noindent Die Komplexität des unstrukturierten Suchproblems ergibt sich daraus, wie viele Iterationen der Funktion erforderlich sind, um das gesuchte Element zu finden. Da wir keine Informationen über die Funktion besitzen, benötigen wir im schlechtesten Fall $N - 1$ Funktionsauswertungen, wobei $N = 2^n$ gilt. Auf diese Weise prüfen wir alle möglichen Eingaben. Ähnlich wie im Beispiel mit den Karten entspricht $N$ dem letzten Element, vorausgesetzt, die vorherigen wurden bereits geprüft. Der Grover-Algorithmus kann dieses Problem jedoch deutlich schneller lösen und erreicht dabei eine quadratische Laufzeitverbesserung.


\subsection{Aufbau von dem Grover Algorithmus}
\subsection{Geometrische Darstellung}
\subsection{Komplexitätsanalyse}
Der Grover-Algorithmus (1996) führt eine quantengestützte Suche durch, indem er sukzessive die Amplitude des gesuchten Zustands verstärkt. Nach etwa $\sqrt{N}$ Iterationen erhält man das Ziel mit hoher Wahrscheinlichkeit.\\
Dieser Algorithmus ist informationstheoretisch optimal für die unstrukturierte Suche. Er wird typischerweise durch eine Schleife aus Orakel-Abfrage (markiert das gesuchte Element) und Inversion der Amplituden um den Mittelwert realisiert.\\
Grover findet Anwendungen als Subroutine in vielen Quantenalgorithmen (z.B. für Optimierung oder Simulation), etwa zur Stichprobensuche oder in hybriden Ansätzen.

\subsection{Amplitudenverstärkung}

Amplitudenverstärkung ist eine Verallgemeinerung des Grover-Algorithmus: Sie erhöht die Erfolgswahrscheinlichkeit eines beliebigen Quantenalgorithmus, der mit Wahrscheinlichkeit $a$ ein Ergebnis liefert, auf $O(1/\sqrt{a})$ Wiederholungen.\\
Das Verfahren erlaubt es, den Aufwand zu halbieren, wenn man weiß, dass ein Ergebnis mit bestimmter Wahrscheinlichkeit auftaucht. Es ist also eine universelle Methode, um Algorithmen (nicht nur Suche) zu beschleunigen.\\
In heuristischen oder iterativen Suchalgorithmen kann Amplitudenverstärkung eingesetzt werden, um die Anzahl der Versuche zur Lösungssuche zu reduzieren; dies erfordert jedoch in der Regel Abschätzungen der Erfolgswahrscheinlichkeit.

\subsection{Quantenlauf-Suchalgorithmen}

Neben dem Grover-Ansatz gibt es Suchalgorithmen auf Basis von Quantenläufen (Quantum Walks). Hier wird die klassische zufällige Suche durch einen quantenmechanischen Spaziergang auf einem Graphen ersetzt.\\
Solche Algorithmen können z.B. die Suche in speziellen Strukturen beschleunigen: Etwa wird auf einem zweidimensionalen Gitter in $O(\sqrt{N\log N})$ statt $O(N)$ Schritten gesucht. Weitere Anwendungen sind die Elementar-Unterscheidung oder die Suche in sozialen Netzwerken.\\
Einführende Übersichten (z.B. Ambainis 2004) fassen die wichtigsten Suchalgorithmen anhand von Quantenläufen und ihre Komplexitäten zusammen.

\subsection{Praxisanwendung und Stand der Technik}

Grover’s Algorithmus wurde bereits auf ersten Quantenrechnern experimentell getestet. So implementierte IBM mit einem 127-Qubit-Supersystem eine 3-Qubit-Grover-Schaltung und untersuchte deren Leistung.\\
Der praktische Einsatz ist derzeit wegen begrenzter Qubit-Zahlen, niedriger Kohärenzzeiten und Fehlerraten noch eingeschränkt. Meist dienen kleine Grover-Experimente als Benchmark für Hardware.\\
Zukünftige Anwendungen könnten in Bereichen wie Datenbankrecherche, Kryptanalyse (Brute-Force-Angriffe) oder NISQ-nahe Optimierungsaufgaben liegen; der Fortschritt in Hardware-Fehlerkorrektur wird entscheidend sein.

\section{Quantumoptimierung}
Quantum-Optimierungsalgorithmen zielen darauf ab, kombinatorische und numerische Optimierungsprobleme schneller zu lösen oder mindestens gute Approximationslösungen zu finden. Typische Ansätze sind der Quanten-Aiabatischer Algorithmus (Quantenannealing) für NP-Probleme, hybride Algorithmen wie VQE und QAOA für Optimierung mit Quanten-Schaltkreisen, sowie Algorithmen zur Lösung linearer Gleichungssysteme (etwa HHL), die in Optimierungs- und Datenanalyseanwendungen münden.

\subsection{Adiabatische Optimierung}

Der Quanten-adiabatische Algorithmus (Farhi et al., 2000) übersetzt kombinatorische Probleme wie 3-SAT in die Suche nach dem Grundzustand eines zeitabhängigen Hamiltonians.\\
Man beginnt im Grundzustand eines einfachen Anfangs-Hamiltonians und ändert langsam zum Zielfall, dessen Grundzustand die Lösung enthält. Nach dem adiabatischen Theorem landet man bei entsprechender Langsamkeit im gewünschten Zustand.\\
Die benötigte Laufzeit hängt vom Energieabstand (Gap) zwischen dem Grund- und dem ersten angeregten Zustand ab. In allgemeinen Fällen ist dieser Abstand schwer abzuschätzen, weshalb eine polynomielle Laufzeit nur für spezielle Problemklassen nachgewiesen wurde.\\

\subsection{Variationaler Quanten-Eigenlöser (VQE)}

Der VQE-Algorithmus (Peruzzo et al., 2014) nutzt das Variationsprinzip auf Quantencomputern: Ein parametrisiertes Quantenschaltkreis $\ket{\psi(\vec\theta)}$ wird auf einen Hamiltonian angewandt, dessen Erwartungswert energetisch bewertet wird. Ein klassischer Optimierer passt die Parameter $\vec\theta$ an, um die Energie zu minimieren.\\
VQE eignet sich insbesondere zur Berechnung von Grundzustandsenergien in Quantenchemie und Festkörperphysik. Dieser hybride Ansatz kann komplexe Vielteilchensysteme in polynomialer Zeit simulieren und ist wegen geringer Quantenressourcen auch für Noisy Intermediate-Scale Quantum (NISQ) Geräte vielversprechend.\\
Trotz der theoretisch guten Skalierung müssen in der Praxis Laufzeit und Güte (sogenannte Pre-Faktoren) sorgfältig abgeschätzt werden; Rauschresistenz ist ein weiterer Vorteil von VQE.

\subsection{Quanten-Algorithmus zur näherungsweisen Optimierung (QAOA)}

QAOA (Farhi et al., 2014) ist ein hybrider Ansatz zur kombinatorischen Optimierung: Er wechselt zwischen „Kosten“- und „Mixer“-Hamiltonians mit tunbaren Parametern in $p$ Schritten.\\
Durch Abstimmung dieser Parameter mithilfe eines klassischen Optimierers können gute Näherungslösungen für Probleme wie MaxCut oder andere NP-harte Optimierungsaufgaben gefunden werden. Die Qualität der Lösung verbessert sich mit zunehmendem $p$.\\
Die Schaltkreustiefe wächst linear mit $p$ und der Problemgröße; wenn $p$ fest ist, kann man den Algorithmus effizient klassisch vorprozessieren. Die Frage, ob QAOA für bestimmte Probleme gegenüber klassischen Algorithmen Vorteile bietet, wird intensiv erforscht.\\

\subsection{Quantum Data Fitting: Lineare Gleichungssysteme lösen}

Quantum Data Fitting bezieht sich darauf, lineare Regressions- oder Ausgleichsaufgaben mithilfe von Quantenalgorithmen durchzuführen. Kern ist meist der HHL-Algorithmus (Harrow, Hassidim, Lloyd 2009), der lineare Gleichungen $Ax=b$ in Logarithmus-Zeit löst.\\
Beispielsweise kann man Parameter für ein lineares Modell auf einem großen Datensatz bestimmen oder die Qualität einer Kleinste-Quadrate-Anpassung untersuchen.\\
Ein neuer Quantenalgorithmus berechnet effizient die Güte einer linearen Regression über ein exponentiell großes Datenset, indem er das lineare Gleichungssystem quantenmechanisch löst.
 

\section{Quantum-safe Algorithmen in Kryptographie}
\subsection{Aktuelle Stand der Kryptographie}
\subsection{Vektoren in der asymmetrischen Verschlüsselung}

\section{Grover-Algorithmus für Fine-tuning von LLM}
\subsection{Idee: Transformer Architektur}
Transformer-Architekturen (Vaswani et al., 2017) bilden die Grundlage moderner großer Sprachmodelle (LLMs). Sie verwenden Self-Attention-Mechanismen, um in einem Eingabesequenz-Kontext relevante Zusammenhänge zu gewichten.\\
Ein Nachteil ist die quadratische Rechenkomplexität in der Sequenzlänge: Standard-Self-Attention erfordert $O(n^2)$ Operationen für eine Sequenz der Länge $n$. Das limitiert die Effizienz bei langen Eingaben.\\
Dieses Kapitel bietet einen Überblick über Transformer und Attention-Blöcke und ihre Rolle in LLMs, um die Ausgangsbasis für quantenbeschleunigte Ansätze zu erklären.

\subsection{Berechnung der Attention}
Gao et al. (2023) zeigten kürzlich, wie man Grover’s Suche nutzen kann, um die Attention-Matrix in Transformers effizienter zu berechnen. Sie betrachten insbesondere spärliche Attention-Matrizen und erreichen einen polynomialen Quantenvorteil gegenüber klassischen Methoden.\\
Ihr Algorithmus berechnet die relativ kleinen (sparse) Einträge der Attention-Matrix schneller, indem er Suche statt vollständiger Matrixmultiplikation verwendet.\\
Solche Quanten-Transformer sind ein aktives Forschungsthema: Sie könnten zukünftig helfen, die Rechenzeit von LLMs zu reduzieren, indem sie die Aufmerksamkeitsschichten quantenbeschleunigt umsetzen.
\printbibliography
